1
00:00:00,799 --> 00:00:06,720
嗨大家，歡迎來到介紹性 Python 教學，特別關注於影像處理

2
00:00:00,799 --> 00:00:06,720
hi everyone welcome to introductory python tutorials with a special focus on image processing

3
00:00:06,720 --> 00:00:12,240
在這段影片中，我們來看看如何使用編碼器建構單位

4
00:00:06,720 --> 00:00:12,240
 in this video let's have a look at building a unit using encoder

5
00:00:12,240 --> 00:00:13,360
和解碼塊

6
00:00:12,240 --> 00:00:13,360
 and decoder blocks

7
00:00:13,360 --> 00:00:17,279
那意味著什麼？在教程 115 中，那個

8
00:00:13,360 --> 00:00:17,279
 what does that mean well in tutorial 115 the one

9
00:00:17,279 --> 00:00:21,920
在這之前，不是這個之前的那個，而是再之前的那個，上一個

10
00:00:17,279 --> 00:00:21,920
 before not the one before this but the one before that one the previous one

11
00:00:21,920 --> 00:00:23,359
我們查看了單位

12
00:00:21,920 --> 00:00:23,359
 we looked at unit

13
00:00:23,359 --> 00:00:30,080
然後我們實際上通過定義每一層來建立單位，就像我們定義了兩個卷積層一樣

14
00:00:23,359 --> 00:00:30,080
 and we actually built unit by defining every layer like we defined two convolution layers

15
00:00:30,080 --> 00:00:31,760
然後是激活層對吧

16
00:00:30,080 --> 00:00:31,760
 and then activation right

17
00:00:31,760 --> 00:00:37,200
然後我們定義了卷積層，抱歉，還有最大池化，兩個卷積層和最大池化

18
00:00:31,760 --> 00:00:37,200
 and then we defined convolution layer sorry and max pooling two convolution layers max pooling

19
00:00:37,200 --> 00:00:38,320
以此類推

20
00:00:37,200 --> 00:00:38,320
 and so on

21
00:00:38,320 --> 00:00:42,640
我們意識到有一些模式這些區塊在重複

22
00:00:38,320 --> 00:00:42,640
 and we realized that there are some patterns these blocks are repeating

23
00:00:42,640 --> 00:00:45,920
那麼如何將這些定義為單獨的函數呢

24
00:00:42,640 --> 00:00:45,920
 so how about defining those as separate functions

25
00:00:45,920 --> 00:00:46,719
編碼器

26
00:00:45,920 --> 00:00:46,719
 for encoder

27
00:00:46,719 --> 00:00:47,440
和解碼器

28
00:00:46,719 --> 00:00:47,440
 and decoder

29
00:00:47,440 --> 00:00:50,000
然後實際上用幾行代碼構建一個單元

30
00:00:47,440 --> 00:00:50,000
 and then actually with a few lines of code build a unit

31
00:00:50,000 --> 00:00:51,360
這樣做可能非常有用

32
00:00:50,000 --> 00:00:51,360
 and this can be very useful

33
00:00:51,360 --> 00:00:57,280
如果你真的希望定義一個幾乎像是通用的單位

34
00:00:51,360 --> 00:00:57,280
 if you really would like to define a almost like a universal unit

35
00:00:57,280 --> 00:00:59,760
只需更改幾個參數

36
00:00:57,280 --> 00:00:59,760
 where you just change a couple of parameters

37
00:00:59,760 --> 00:01:03,520
然後您可以將此功能自訂為二元分割

38
00:00:59,760 --> 00:01:03,520
 and then you can customize this for binary segmentation

39
00:01:03,520 --> 00:01:05,840
您可以將此功能自訂為多類別分割

40
00:01:03,520 --> 00:01:05,840
 you can customize this for multi-class segmentation

41
00:01:05,840 --> 00:01:08,720
那麼擴展到 3D 主題怎麼樣

42
00:01:05,840 --> 00:01:08,720
 how about extending this to 3d topic

43
00:01:08,720 --> 00:01:09,760
對，所以你可以，你可以

44
00:01:08,720 --> 00:01:09,760
 right so you can you can

45
00:01:09,760 --> 00:01:11,040
你可以自己建造單位

46
00:01:09,760 --> 00:01:11,040
 you can build your own units

47
00:01:11,040 --> 00:01:12,880
這不是非常困難

48
00:01:11,040 --> 00:01:12,880
 this is not very difficult

49
00:01:12,880 --> 00:01:15,920
那我們就來看看怎麼做到這點

50
00:01:12,880 --> 00:01:15,920
 so let's go ahead and see how we can do that

51
00:01:15,920 --> 00:01:22,799
再次快速回顧這個單元，這是原始文獻中的單元

52
00:01:15,920 --> 00:01:22,799
 and again a quick recap of unit this is the unit from original paper

53
00:01:22,799 --> 00:01:24,320
和

54
00:01:22,799 --> 00:01:24,320
 and

55
00:01:24,320 --> 00:01:26,080
如您所見，我們正在往下進行

56
00:01:24,320 --> 00:01:26,080
 as you can see we are going down

57
00:01:26,080 --> 00:01:29,680
隨著我們往下進行，會有一些特定的操作

58
00:01:26,080 --> 00:01:29,680
 and there are certain specific operations as we go down

59
00:01:29,680 --> 00:01:34,000
以及在視頻 115 教學 115 中

60
00:01:29,680 --> 00:01:34,000
 and in the video 115 tutorial 115

61
00:01:34,000 --> 00:01:37,920
我們檢視了使用 256 x 256 來實現這個單元

62
00:01:34,000 --> 00:01:37,920
 we looked at implementing this unit using 256 by 256

63
00:01:37,920 --> 00:01:40,880
1 圖像，這裡是我們檢視的結構

64
00:01:37,920 --> 00:01:40,880
 1 images here is the structure that we looked at

65
00:01:40,880 --> 00:01:44,320
我們說好，從 256 減少到 128

66
00:01:40,880 --> 00:01:44,320
 and we said okay going from 256 to 128

67
00:01:44,320 --> 00:01:51,360
減少到 64，然後到 32，再到 16。再次觀看最後的影片以了解這個解碼器部分

68
00:01:44,320 --> 00:01:51,360
 to 64 to 32 to 16 right again watch the last video to understand this decoder part

69
00:01:51,360 --> 00:01:53,040
我們討論了上採樣

70
00:01:51,360 --> 00:01:53,040
 we talked about up sampling

71
00:01:53,040 --> 00:01:56,079
我們也談到了 2D 轉置

72
00:01:53,040 --> 00:01:56,079
 we also talked about con 2d transpose either way

73
00:01:56,079 --> 00:02:00,240
從 16 x 16 到 32，再到 64，再到 128

74
00:01:56,079 --> 00:02:00,240
 you're going from 16 by 16 to 32 to 64 to 128

75
00:02:00,240 --> 00:02:01,680
最終到 256

76
00:02:00,240 --> 00:02:01,680
 and finally to 256

77
00:02:01,680 --> 00:02:04,079
這恰好是我們圖像的原始大小

78
00:02:01,680 --> 00:02:04,079
 which happens to be the original size of our image

79
00:02:04,079 --> 00:02:08,160
因為您希望分割後的圖像與原始圖像大小相同

80
00:02:04,079 --> 00:02:08,160
 because you want your segmented image to be the same size as your original image

81
00:02:08,160 --> 00:02:09,119
好的

82
00:02:08,160 --> 00:02:09,119
 yeah

83
00:02:09,119 --> 00:02:10,160
所以

84
00:02:09,119 --> 00:02:10,160
 so

85
00:02:10,160 --> 00:02:13,680
我們是通過在這裡編寫每一行來構建這個的

86
00:02:10,160 --> 00:02:13,680
 we built this by writing each line here

87
00:02:13,680 --> 00:02:15,120
所以這是我的輸入

88
00:02:13,680 --> 00:02:15,120
 so this is my input

89
00:02:15,120 --> 00:02:16,879
然後接著是兩個卷積層

90
00:02:15,120 --> 00:02:16,879
 and then comes two convolutional layers

91
00:02:16,879 --> 00:02:20,720
以及最大池化，兩個卷積，最大池化，右側，這正是

92
00:02:16,879 --> 00:02:20,720
 and max pooling two convolution max pooling right this is exactly

93
00:02:20,720 --> 00:02:22,319
我們有兩個卷積

94
00:02:20,720 --> 00:02:22,319
 what we have two convolutions

95
00:02:22,319 --> 00:02:26,640
藍色箭頭最大池化，紅色箭頭兩個卷積，藍色箭頭，紅色箭頭

96
00:02:22,319 --> 00:02:26,640
 the blue arrows max pulling red arrow two convolution blue arrows red arrow

97
00:02:26,640 --> 00:02:30,319
然後我們意識到有一堆這些內容在重複

98
00:02:26,640 --> 00:02:30,319
 and so on then we realized a bunch of these are repeating

99
00:02:30,319 --> 00:02:32,879
那為什麼不直接分配區塊呢

100
00:02:30,319 --> 00:02:32,879
 so why not just assign blocks

101
00:02:32,879 --> 00:02:33,280
所以

102
00:02:32,879 --> 00:02:33,280
 so

103
00:02:33,280 --> 00:02:36,080
那我們這麼說的意思是什麼，例如

104
00:02:33,280 --> 00:02:36,080
 what do we mean by that for example

105
00:02:36,080 --> 00:02:39,280
讓我們來看看這兩個操作

106
00:02:36,080 --> 00:02:39,280
 let's look at these two operations right there

107
00:02:39,280 --> 00:02:44,160
所以我們正在進行卷積，我們正在進行卷積

108
00:02:39,280 --> 00:02:44,160
 so we are performing a convolution right we are performing a convolution convolution

109
00:02:44,160 --> 00:02:46,400
和最大池化

110
00:02:44,160 --> 00:02:46,400
 and max pooling

111
00:02:46,400 --> 00:02:47,760
輸出是什麼

112
00:02:46,400 --> 00:02:47,760
 what is the output

113
00:02:47,760 --> 00:02:49,200
在每個這些之後

114
00:02:47,760 --> 00:02:49,200
 after each of these

115
00:02:49,200 --> 00:02:51,280
所以我正在分配某些

116
00:02:49,200 --> 00:02:51,280
 so i'm assigning certain

117
00:02:51,280 --> 00:02:56,879
我說，卷積層的輸出是 s1

118
00:02:51,280 --> 00:02:56,879
 certain name to it i'm saying okay the output of my convolution layers is s1

119
00:02:56,879 --> 00:03:00,800
在這一點上，我的卷積層的輸出是 s1

120
00:02:56,879 --> 00:03:00,800
 the output of my convolution layers is s1 at this point

121
00:03:00,800 --> 00:03:04,080
最大池化的輸出是 p1

122
00:03:00,800 --> 00:03:04,080
 and the output of max pooling is p1

123
00:03:04,080 --> 00:03:09,440
好的，讓我們回到這個第二次操作的輸出是 s1

124
00:03:04,080 --> 00:03:09,440
 okay let's go back the output of this second operation is s1

125
00:03:09,440 --> 00:03:12,959
池化的輸出是 p1

126
00:03:09,440 --> 00:03:12,959
 and the output of the pooling is p1

127
00:03:12,959 --> 00:03:15,599
一切將會在一秒鐘內完成

128
00:03:12,959 --> 00:03:15,599
 everything will come together in a second

129
00:03:15,599 --> 00:03:16,879
所以

130
00:03:15,599 --> 00:03:16,879
 so

131
00:03:16,879 --> 00:03:21,599
在第一層，convert2d 的輸出是 256

132
00:03:16,879 --> 00:03:21,599
 at the first layer the output of convert2d is 256

133
00:03:21,599 --> 00:03:26,799
因為我們沒有進行任何池化，什麼都沒有，只是會有 64 個濾波器

134
00:03:21,599 --> 00:03:26,799
 because we are not doing any pooling nothing it's just that we'll have 64 filters

135
00:03:26,799 --> 00:03:30,319
到目前為止，這個的大小是 256。

136
00:03:26,799 --> 00:03:30,319
 at this point the size of this is 256.

137
00:03:30,319 --> 00:03:32,080
我們有 64 個過濾器

138
00:03:30,319 --> 00:03:32,080
 we have 64 filters

139
00:03:32,080 --> 00:03:35,200
在最大池化後，大小縮小到 128。

140
00:03:32,080 --> 00:03:35,200
 after max pooling the size goes down to 128.

141
00:03:35,200 --> 00:03:36,720
現在回到代碼

142
00:03:35,200 --> 00:03:36,720
 now go back to the code

143
00:03:36,720 --> 00:03:38,400
所以在這一點上

144
00:03:36,720 --> 00:03:38,400
 so at this point

145
00:03:38,400 --> 00:03:40,879
s1 的大小為 256

146
00:03:38,400 --> 00:03:40,879
 s1 has a size of 256

147
00:03:40,879 --> 00:03:44,000
p1 的大小為 128

148
00:03:40,879 --> 00:03:44,000
 p1 has a size of 128.

149
00:03:44,000 --> 00:03:46,400
這裡的 s2 大小為 128

150
00:03:44,000 --> 00:03:46,400
 here s2 has a size of 128

151
00:03:46,400 --> 00:03:46,879
因為

152
00:03:46,400 --> 00:03:46,879
 because

153
00:03:46,879 --> 00:03:51,599
s2 是什麼？它來自 p1 的輸入

154
00:03:46,879 --> 00:03:51,599
 what is s2 it's coming the input from p1

155
00:03:51,599 --> 00:03:55,280
是的，我們再來看一下這個圖示

156
00:03:51,599 --> 00:03:55,280
 yeah again let's look at this in the diagram here

157
00:03:55,280 --> 00:04:00,959
所以這是輸入，這是 p1，這個輸入進入了我的 s2

158
00:03:55,280 --> 00:04:00,959
 so this is the input this is the p1 that input is going into my s2

159
00:04:00,959 --> 00:04:03,360
好，就在那裡

160
00:04:00,959 --> 00:04:03,360
 okay right there

161
00:04:03,360 --> 00:04:03,920
然後

162
00:04:03,360 --> 00:04:03,920
 and then

163
00:04:03,920 --> 00:04:07,360
在 s2 操作之後，你會得到下一步

164
00:04:03,920 --> 00:04:07,360
 after the s2 operation you get the next step

165
00:04:07,360 --> 00:04:08,159
以此類推

166
00:04:07,360 --> 00:04:08,159
 and so on

167
00:04:08,159 --> 00:04:12,400
那麼我們來指定某些參數

168
00:04:08,159 --> 00:04:12,400
 so let's assign certain certain parameters

169
00:04:12,400 --> 00:04:12,959
變數

170
00:04:12,400 --> 00:04:12,959
 variables

171
00:04:12,959 --> 00:04:16,079
因此，這讓我們容易定義我們的模型

172
00:04:12,959 --> 00:04:16,079
 so it makes it easy for us to define our model

173
00:04:16,079 --> 00:04:20,000
所以假設卷積輸出是 s1

174
00:04:16,079 --> 00:04:20,000
 so let's say the convolution output is s1

175
00:04:20,000 --> 00:04:23,040
而最大池化輸出是那裡的 p1

176
00:04:20,000 --> 00:04:23,040
 and the max pooling output is p1 right there

177
00:04:23,040 --> 00:04:27,120
在這一點，這個箭頭的尖端，這兩件事

178
00:04:23,040 --> 00:04:27,120
 at this point at the tip of this arrow the two things

179
00:04:27,120 --> 00:04:30,320
我們需要的其中之一是 s1

180
00:04:27,120 --> 00:04:30,320
 that we need one is s1

181
00:04:30,320 --> 00:04:35,040
另一個是 p1，s1 對應於這個卷積層的輸出

182
00:04:30,320 --> 00:04:35,040
 the other one is p1 s1 corresponds to the output of this convolution layer

183
00:04:35,040 --> 00:04:38,880
和 p1 對應於這個最大池化的輸出

184
00:04:35,040 --> 00:04:38,880
 and p1 corresponds to the output of this max pooling that goes

185
00:04:38,880 --> 00:04:42,720
作為下一個的輸入，為什麼我們需要卷積的輸出

186
00:04:38,880 --> 00:04:42,720
 as input to the next one why do we need the output of convolution

187
00:04:42,720 --> 00:04:46,400
在最大池化之前，當我們說這個時候，我在說輸出

188
00:04:42,720 --> 00:04:46,400
 before max pooling right when we say that i'm saying output

189
00:04:46,400 --> 00:04:49,280
在最大池化之前，為什麼我需要那個？我需要那個

190
00:04:46,400 --> 00:04:49,280
 before max pooling why do i need that well i need that

191
00:04:49,280 --> 00:04:54,639
這樣我才能將該輸出發送到這一層進行串接

192
00:04:49,280 --> 00:04:54,639
 so i can send that output to this layer right here for concatenation

193
00:04:54,639 --> 00:04:55,840
這就是單元的作用

194
00:04:54,639 --> 00:04:55,840
 that's what unit is

195
00:04:55,840 --> 00:04:58,880
那麼如果我們回來，我拿我的 S1

196
00:04:55,840 --> 00:04:58,880
 so if we come back if i take my s1

197
00:04:58,880 --> 00:05:03,440
那個 S1 連接到 D4 就在那裡，這就是原因

198
00:04:58,880 --> 00:05:03,440
 that s1 is connected to d4 right there this is the reason

199
00:05:03,440 --> 00:05:07,039
我希望我的 S1 作為單獨的輸出

200
00:05:03,440 --> 00:05:07,039
 i want my s1 as a separate output

201
00:05:07,039 --> 00:05:08,479
我希望到目前為止一切順利

202
00:05:07,039 --> 00:05:08,479
 i hope so far so good

203
00:05:08,479 --> 00:05:12,639
那麼我們現在繼續這個，所以 s1 p1 s2 p2 s3 p3

204
00:05:08,479 --> 00:05:12,639
 so let's now continue this so s1 p1 s2 p2 s3 p3

205
00:05:12,639 --> 00:05:15,199
每完成這些後，你會得到

206
00:05:12,639 --> 00:05:15,199
 after each of these you get

207
00:05:15,199 --> 00:05:18,240
卷積輸出最大拉伸輸出

208
00:05:15,199 --> 00:05:18,240
 the convolution output max pulling output

209
00:05:18,240 --> 00:05:21,120
而且你就有了基底

210
00:05:18,240 --> 00:05:21,120
 and you have the base right there

211
00:05:21,120 --> 00:05:23,039
好的，就在這裡

212
00:05:21,120 --> 00:05:23,039
 okay right here

213
00:05:23,039 --> 00:05:29,120
在這之後，我們會向上移動，同時我們會有我們的解碼器，一個解碼器

214
00:05:23,039 --> 00:05:29,120
 after this we are going up while going up we have our our decoder one decoder

215
00:05:29,120 --> 00:05:30,639
我們不需要發送

216
00:05:29,120 --> 00:05:30,639
 two we don't need to send

217
00:05:30,639 --> 00:05:33,600
當我們上升時會有兩個輸出，因為我們沒有做任何事

218
00:05:30,639 --> 00:05:33,600
 two outputs while we are going up because we are not doing

219
00:05:33,600 --> 00:05:36,880
我們所需要的只是來自這裡的輸出

220
00:05:33,600 --> 00:05:36,880
 anything with that all we need is output from here

221
00:05:36,880 --> 00:05:41,039
這可以作為輸入提供給下一個解碼器區塊

222
00:05:36,880 --> 00:05:41,039
 that can be provided as input to the next decoder block

223
00:05:41,039 --> 00:05:45,199
所以每個解碼區塊編碼區塊我們稍後會定義

224
00:05:41,039 --> 00:05:45,199
 so each of this decoder block encoder block we'll define that in a second

225
00:05:45,199 --> 00:05:47,440
所以輸出是 d1 d2 d3

226
00:05:45,199 --> 00:05:47,440
 so the outputs are d1 d2 d3

227
00:05:47,440 --> 00:05:51,280
然後 d4 基本上是朝向你的輸出

228
00:05:47,440 --> 00:05:51,280
 and then d4 is basically going towards your output

229
00:05:51,280 --> 00:05:54,080
現在讓我們定義一下，識別一些重複的

230
00:05:51,280 --> 00:05:54,080
 so now let's define let's identify some repetitive

231
00:05:54,080 --> 00:05:58,400
模式。這裡你可以看到藍色的框，這些是重複的

232
00:05:54,080 --> 00:05:58,400
 patterns here you see the blue boxes here these are repetitive

233
00:05:58,400 --> 00:05:59,520
卷積塊

234
00:05:58,400 --> 00:05:59,520
 convolutional blocks

235
00:05:59,520 --> 00:06:03,120
如果你只看這兩個藍色箭頭，就是這樣

236
00:05:59,520 --> 00:06:03,120
 if you just look at this two blue arrows that's it

237
00:06:03,120 --> 00:06:05,919
兩個藍色箭頭 兩個藍色箭頭 兩個藍色箭頭

238
00:06:03,120 --> 00:06:05,919
 two blue arrows two blue arrows two blue arrows

239
00:06:05,919 --> 00:06:10,720
即使是回到上面，你也有卷積層對吧

240
00:06:05,919 --> 00:06:10,720
 and so on even going back up you have the convolution layers right

241
00:06:10,720 --> 00:06:12,960
為什麼不將其定義為一個函數

242
00:06:10,720 --> 00:06:12,960
 so why not define that as a function

243
00:06:12,960 --> 00:06:14,800
這是第一步，我們會這麼做

244
00:06:12,960 --> 00:06:14,800
 that's step number one we'll do that

245
00:06:14,800 --> 00:06:16,000
那我們要怎麼做呢

246
00:06:14,800 --> 00:06:16,000
 and how do we do that

247
00:06:16,000 --> 00:06:21,199
所以在我們的情況下，卷積區塊我們要定義的方式是 convert2d

248
00:06:16,000 --> 00:06:21,199
 so in our case the convolution block the way we are going to define is convert2d

249
00:06:21,199 --> 00:06:23,280
對，那是 conf2d

250
00:06:21,199 --> 00:06:23,280
 right that's conf2d

251
00:06:23,280 --> 00:06:25,280
然後你可以定義下一個 2D 轉換

252
00:06:23,280 --> 00:06:25,280
 and then you can define the next conver 2d

253
00:06:25,280 --> 00:06:27,759
但我正在添加批量正則化

254
00:06:25,280 --> 00:06:27,759
 but i am adding batch normalization

255
00:06:27,759 --> 00:06:33,199
所以這有點平衡了事物，批量正則化非常好

256
00:06:27,759 --> 00:06:33,199
 so it it kind of balances things out bash normalization is very good

257
00:06:33,199 --> 00:06:35,280
你知道，它使得融合變得稍微容易一些

258
00:06:33,199 --> 00:06:35,280
 you know it it makes convergence

259
00:06:35,280 --> 00:06:39,199
讓我這麼說吧，再次觀看批次正規化的影片

260
00:06:35,280 --> 00:06:39,199
 a bit easier let me put it that way again watch the video on batch normalization

261
00:06:39,199 --> 00:06:41,919
但只是快速提醒一下

262
00:06:39,199 --> 00:06:41,919
 but just a quick note

263
00:06:41,919 --> 00:06:47,840
所以這個矩形上面寫著 64，就是這部分代碼

264
00:06:41,919 --> 00:06:47,840
 so this rectangle that says 64 up here is this part of the code

265
00:06:47,840 --> 00:06:51,759
基本上是 convert2d 加上批量正規化

266
00:06:47,840 --> 00:06:51,759
 which is basically convert2d with batch normalization

267
00:06:51,759 --> 00:06:54,880
然後應用 Rayleigh 激活函數，就是這樣

268
00:06:51,759 --> 00:06:54,880
 and then applying rayleigh activation right so here

269
00:06:54,880 --> 00:06:59,280
將濾波器大小設為三乘三

270
00:06:54,880 --> 00:06:59,280
 con to a three by three is my filter size right there

271
00:06:59,280 --> 00:07:00,880
然後是射頻激活

272
00:06:59,280 --> 00:07:00,880
 and then radioactivation

273
00:07:00,880 --> 00:07:04,080
我做的就是添加偏差正規化，就這樣

274
00:07:00,880 --> 00:07:04,080
 all i did is add bias normalization that's it

275
00:07:04,080 --> 00:07:06,160
然後第二個就在那裡

276
00:07:04,080 --> 00:07:06,160
 and then the second one right there

277
00:07:06,160 --> 00:07:10,319
這與第一個相當相似，對立批次啟用

278
00:07:06,160 --> 00:07:10,319
 which is pretty much the same as the first one contrary batch activation

279
00:07:10,319 --> 00:07:13,120
這是我的卷積區塊

280
00:07:10,319 --> 00:07:13,120
 this is my convolution block

281
00:07:13,120 --> 00:07:14,000
好的

282
00:07:13,120 --> 00:07:14,000
 okay

283
00:07:14,000 --> 00:07:16,479
還有什麼在重複

284
00:07:14,000 --> 00:07:16,479
 what else is repeating

285
00:07:16,479 --> 00:07:18,720
這個區塊正在重複

286
00:07:16,479 --> 00:07:18,720
 this block is repeating

287
00:07:18,720 --> 00:07:22,319
卷積區塊加上最大池化

288
00:07:18,720 --> 00:07:22,319
 convolution block plus max pooling

289
00:07:22,319 --> 00:07:23,280
我的意思是你可能會認為

290
00:07:22,319 --> 00:07:23,280
 i mean you may think

291
00:07:23,280 --> 00:07:27,280
這些是相同的，藍色框直到那一點沒有最大池化

292
00:07:23,280 --> 00:07:27,280
 these are the same the blue box is up to that point without max pooling

293
00:07:27,280 --> 00:07:29,440
紅色框是使用最大池化

294
00:07:27,280 --> 00:07:29,440
 the red box is with max pooling

295
00:07:29,440 --> 00:07:31,680
這在編碼器中也重複出現

296
00:07:29,440 --> 00:07:31,680
 this is also repeating in the encoder

297
00:07:31,680 --> 00:07:34,479
四乘一二三四

298
00:07:31,680 --> 00:07:34,479
 four times one two three four

299
00:07:34,479 --> 00:07:37,039
那麼我們來定義編碼器區塊

300
00:07:34,479 --> 00:07:37,039
 so let's define the encoder block

301
00:07:37,039 --> 00:07:37,759
這什麼都不是

302
00:07:37,039 --> 00:07:37,759
 which is nothing

303
00:07:37,759 --> 00:07:40,880
但這是卷積區塊的組合

304
00:07:37,759 --> 00:07:40,880
 but a combination of convolution block

305
00:07:40,880 --> 00:07:42,840
和最大

306
00:07:40,880 --> 00:07:42,840
 and max

307
00:07:42,840 --> 00:07:43,919
池化

308
00:07:42,840 --> 00:07:43,919
 pooling

309
00:07:43,919 --> 00:07:48,160
這個編碼器區塊給我們兩個輸出 s1

310
00:07:43,919 --> 00:07:48,160
 and this encoder block is giving us two outputs s1

311
00:07:48,160 --> 00:07:48,960
或 s

312
00:07:48,160 --> 00:07:48,960
 or s

313
00:07:48,960 --> 00:07:52,160
而 p 正確，這裡我叫它 x

314
00:07:48,960 --> 00:07:52,160
 and p right again here i called it x

315
00:07:52,160 --> 00:07:53,840
但把這個視為 s

316
00:07:52,160 --> 00:07:53,840
 but think of this as s

317
00:07:53,840 --> 00:07:54,400
好的

318
00:07:53,840 --> 00:07:54,400
 okay

319
00:07:54,400 --> 00:07:59,280
這是來自卷積區塊的輸出，即你的 x

320
00:07:54,400 --> 00:07:59,280
 which is the output from convolution block is your x

321
00:07:59,280 --> 00:08:01,440
而 p 是來自最大池化的輸出

322
00:07:59,280 --> 00:08:01,440
 and p is the output from the max pooling

323
00:08:01,440 --> 00:08:02,400
所以這是這兩個

324
00:08:01,440 --> 00:08:02,400
 so these are the two

325
00:08:02,400 --> 00:08:05,680
你知道我們為什麼需要 x，我們需要 x

326
00:08:02,400 --> 00:08:05,680
 and you know exactly why we need x we need x

327
00:08:05,680 --> 00:08:09,120
這樣我們就可以與任何那個進行連接

328
00:08:05,680 --> 00:08:09,120
 so we can concatenate with whatever that

329
00:08:09,120 --> 00:08:11,039
d 在那邊

330
00:08:09,120 --> 00:08:11,039
 d is over there

331
00:08:11,039 --> 00:08:12,080
我們需要 p

332
00:08:11,039 --> 00:08:12,080
 we need p

333
00:08:12,080 --> 00:08:15,039
這樣可以進入下一個卷積塊

334
00:08:12,080 --> 00:08:15,039
 so that can go into the next convolution block

335
00:08:15,039 --> 00:08:17,599
或者編碼器塊，如果你想這麼稱呼的話

336
00:08:15,039 --> 00:08:17,599
 or encoder block if you want to call it

337
00:08:17,599 --> 00:08:18,000
好的

338
00:08:17,599 --> 00:08:18,000
 okay

339
00:08:18,000 --> 00:08:19,520
還有什麼在重複

340
00:08:18,000 --> 00:08:19,520
 what else is repeating

341
00:08:19,520 --> 00:08:24,879
這些綠色的方塊，對，就是這些，它們是解碼塊。我們之前有編碼塊在下方。

342
00:08:19,520 --> 00:08:24,879
 these green boxes right these are decoded blocks previously we had encoder blocks going down

343
00:08:24,879 --> 00:08:28,080
現在我們有了解碼塊。編碼塊和解碼塊之間有什麼區別？

344
00:08:24,879 --> 00:08:28,080
 now we have decoder block what's the difference between encoder

345
00:08:28,080 --> 00:08:30,479
和解碼塊，它們有點對稱。

346
00:08:28,080 --> 00:08:30,479
 and decoder block they're kind of symmetric

347
00:08:30,479 --> 00:08:32,479
但在這裡我們有連接

348
00:08:30,479 --> 00:08:32,479
 but here we have concatenation

349
00:08:32,479 --> 00:08:34,000
所以我們需要添加它

350
00:08:32,479 --> 00:08:34,000
 so we need to add that

351
00:08:34,000 --> 00:08:38,080
所以讓我們繼續添加它，我的解碼器區塊接收輸入

352
00:08:34,000 --> 00:08:38,080
 so let's go ahead and add it my decoder block takes in input

353
00:08:38,080 --> 00:08:40,159
從前一層

354
00:08:38,080 --> 00:08:40,159
 from the previous layer

355
00:08:40,159 --> 00:08:42,799
跳過功能是快捷方式

356
00:08:40,159 --> 00:08:42,799
 skip features are the shortcuts

357
00:08:42,799 --> 00:08:43,839
他們稱之為

358
00:08:42,799 --> 00:08:43,839
 they call the

359
00:08:43,839 --> 00:08:47,600
我是說，這是用來跳過功能的快捷鍵的常見術語

360
00:08:43,839 --> 00:08:47,600
 i mean it's common terminology for the shortcuts are skip features

361
00:08:47,600 --> 00:08:48,959
所以這就是那個意思

362
00:08:47,600 --> 00:08:48,959
 so that's what that is

363
00:08:48,959 --> 00:08:52,000
和過濾器的數量

364
00:08:48,959 --> 00:08:52,000
 and number of filters

365
00:08:52,480 --> 00:08:54,320
那麼首先會發生什麼操作

366
00:08:52,480 --> 00:08:54,320
 so what operation happens first

367
00:08:54,320 --> 00:08:59,519
你可以看到這裡兩兩對話，所以我們將進行 2D 轉置

368
00:08:54,320 --> 00:08:59,519
 you see up here up convo two by two so we are going to perform con 2d transpose

369
00:08:59,519 --> 00:09:02,240
或者你可以進行上採樣，然後再進行卷積

370
00:08:59,519 --> 00:09:02,240
 or you can do up sampling you know followed by convolution

371
00:09:02,240 --> 00:09:05,760
但這只是遵循這種矛盾轉置

372
00:09:02,240 --> 00:09:05,760
 but this this just follow this contradi transpose

373
00:09:05,760 --> 00:09:07,120
並且需要多個濾波器

374
00:09:05,760 --> 00:09:07,120
 and it takes number of filters

375
00:09:07,120 --> 00:09:10,320
所以如果我說我的濾波器數量是 256

376
00:09:07,120 --> 00:09:10,320
 so if my if i say my number of filters is 256

377
00:09:10,320 --> 00:09:14,320
這就是我如果過濾器數量為 128 時得到的結果

378
00:09:10,320 --> 00:09:14,320
 that's what i get if my number of filters is 128 that's what i get

379
00:09:14,320 --> 00:09:18,880
在這個綠色列之後的 2D 操作到這個輸出

380
00:09:14,320 --> 00:09:18,880
 after this green column 2d operation to this output

381
00:09:18,880 --> 00:09:21,920
我需要添加從那裡來的輸入

382
00:09:18,880 --> 00:09:21,920
 i need to add the input coming from there

383
00:09:21,920 --> 00:09:22,640
所以這正是

384
00:09:21,920 --> 00:09:22,640
 so that's exactly

385
00:09:22,640 --> 00:09:25,040
跳過計數功能的用途

386
00:09:22,640 --> 00:09:25,040
 what the skip count features are for

387
00:09:25,040 --> 00:09:26,959
所以連接

388
00:09:25,040 --> 00:09:26,959
 so concatenate

389
00:09:26,959 --> 00:09:28,480
這個輸出

390
00:09:26,959 --> 00:09:28,480
 this output

391
00:09:28,480 --> 00:09:32,320
和跳過功能一起，這就是那個區塊

392
00:09:28,480 --> 00:09:32,320
 and the skip features together this is that block right there

393
00:09:32,320 --> 00:09:34,000
一旦你連接

394
00:09:32,320 --> 00:09:34,000
 and once you concatenate

395
00:09:34,000 --> 00:09:38,640
添加卷積區塊，記住這部分是 Karma 區塊

396
00:09:34,000 --> 00:09:38,640
 add the convolution block remember this part is the karma block

397
00:09:38,640 --> 00:09:43,680
對，我們重複這樣做只是為了說明這部分，藍色框是卷積

398
00:09:38,640 --> 00:09:43,680
 right we're repeating it just to say this part the blue box is the conve

399
00:09:43,680 --> 00:09:45,279
所以在串接之後

400
00:09:43,680 --> 00:09:45,279
 so after concatenating

401
00:09:45,279 --> 00:09:47,200
就是做那個卷積區塊，正是如此

402
00:09:45,279 --> 00:09:47,200
 just do the convolution block that's exactly

403
00:09:47,200 --> 00:09:50,640
我們嘗試在那裡做的卷積區塊

404
00:09:47,200 --> 00:09:50,640
 what we are trying to do there convolution block

405
00:09:50,640 --> 00:09:52,080
那並不簡單

406
00:09:50,640 --> 00:09:52,080
 isn't that simple

407
00:09:52,080 --> 00:09:52,560
好的

408
00:09:52,080 --> 00:09:52,560
 okay

409
00:09:52,560 --> 00:09:53,920
所以這就是在這裡

410
00:09:52,560 --> 00:09:53,920
 so this is where

411
00:09:53,920 --> 00:09:56,000
現在你可以稍微看到

412
00:09:53,920 --> 00:09:56,000
 now you can kind of see

413
00:09:56,000 --> 00:09:57,279
這如何適合

414
00:09:56,000 --> 00:09:57,279
 how this fits in

415
00:09:57,279 --> 00:09:57,680
好的

416
00:09:57,279 --> 00:09:57,680
 yeah

417
00:09:57,680 --> 00:09:59,680
所以這些輸出

418
00:09:57,680 --> 00:09:59,680
 so these outputs

419
00:09:59,680 --> 00:10:00,000
和

420
00:09:59,680 --> 00:10:00,000
 and

421
00:10:00,000 --> 00:10:04,480
現在讓我們把這些整合在一起以建構這個單元

422
00:10:00,000 --> 00:10:04,480
 now let's put all of this together to build this unit

423
00:10:04,480 --> 00:10:07,360
你如何將它們組合在一起？這樣就可以了

424
00:10:04,480 --> 00:10:07,360
 how do you put them together there you go

425
00:10:07,360 --> 00:10:09,200
所以

426
00:10:07,360 --> 00:10:09,200
 so

427
00:10:09,200 --> 00:10:16,720
在輸入上應用一個具有 64 個濾波器的編碼器區塊，這就是你所得到的

428
00:10:09,200 --> 00:10:16,720
 apply an encoder block on the input with 64 filters there you go that's where you get

429
00:10:16,720 --> 00:10:18,800
編碼器區塊能給你什麼

430
00:10:16,720 --> 00:10:18,800
 and what does an encoder block give you

431
00:10:18,800 --> 00:10:22,399
編碼器區塊給你的輸出是什麼，它給你

432
00:10:18,800 --> 00:10:22,399
 what output does an encoder block give you it gives you

433
00:10:22,399 --> 00:10:26,079
跳過連接就像是卷積區塊的輸出

434
00:10:22,399 --> 00:10:26,079
 the skip connection like the output of the convolution block

435
00:10:26,079 --> 00:10:27,519
和最大池化

436
00:10:26,079 --> 00:10:27,519
 and max pooling

437
00:10:27,519 --> 00:10:30,079
再次重申這一點，因為這很重要

438
00:10:27,519 --> 00:10:30,079
 again i'm repeating this because this is important

439
00:10:30,079 --> 00:10:34,079
第一個，這個 x 是連接的

440
00:10:30,079 --> 00:10:34,079
 the first one this one x is concatenated

441
00:10:34,079 --> 00:10:36,560
p 進入下一級

442
00:10:34,079 --> 00:10:36,560
 p goes to the next level

443
00:10:36,560 --> 00:10:37,040
好的

444
00:10:36,560 --> 00:10:37,040
 okay

445
00:10:37,040 --> 00:10:40,079
那我們回到之前的

446
00:10:37,040 --> 00:10:40,079
 so let's go back

447
00:10:40,720 --> 00:10:42,720
它給你兩樣東西，對吧

448
00:10:40,720 --> 00:10:42,720
 it gives you two things right x

449
00:10:42,720 --> 00:10:44,480
現在我稱它為 s1

450
00:10:42,720 --> 00:10:44,480
 now i'm calling it s1

451
00:10:44,480 --> 00:10:45,519
和 p1

452
00:10:44,480 --> 00:10:45,519
 and p1

453
00:10:45,519 --> 00:10:50,800
p1 是進入下一個編碼器區塊的部分，這是下一個具有 128 的編碼器區塊

454
00:10:45,519 --> 00:10:50,800
 p1 is what goes to the next encoder block right this is the next encoder block with 128

455
00:10:50,800 --> 00:10:55,040
過濾器，就是 p1 的位置，這個編碼器區塊給你 s2

456
00:10:50,800 --> 00:10:55,040
 filters that's where p1 is this encoder block gives you s2

457
00:10:55,040 --> 00:10:56,399
以及 p2 作為輸出

458
00:10:55,040 --> 00:10:56,399
 and p2 as outputs

459
00:10:56,399 --> 00:11:01,839
然後它一直延續到這個基礎 b1

460
00:10:56,399 --> 00:11:01,839
 and then it continues all the way down to this base b1

461
00:11:01,839 --> 00:11:06,800
然後在這裡的解碼器區塊，我們正在處理 b1

462
00:11:01,839 --> 00:11:06,800
 and then the decoder block here we are taking b1

463
00:11:06,800 --> 00:11:08,240
就在那裡

464
00:11:06,800 --> 00:11:08,240
 right there

465
00:11:08,240 --> 00:11:12,560
然後我們將那部分複製到這裡或將那部分連接到這裡

466
00:11:08,240 --> 00:11:12,560
 and then we copy that part here or we concatenate that part here

467
00:11:12,560 --> 00:11:15,839
這是 s4 對吧

468
00:11:12,560 --> 00:11:15,839
 which is s4 right

469
00:11:15,839 --> 00:11:18,640
是的，就在那裡，抱歉，s4

470
00:11:15,839 --> 00:11:18,640
 yeah right there sorry s4

471
00:11:18,640 --> 00:11:22,880
這個是 s4，我把它放在這裡，可能有點混淆

472
00:11:18,640 --> 00:11:22,880
 this one is s4 i put it down here can be a bit confusing

473
00:11:22,880 --> 00:11:26,320
但 s4 是來自這裡的卷積輸出

474
00:11:22,880 --> 00:11:26,320
 but s4 is the convolutional output coming from here

475
00:11:26,320 --> 00:11:28,720
所以你把 s4 和 d1 放在一起

476
00:11:26,320 --> 00:11:28,720
 so you put s4 along with d1

477
00:11:28,720 --> 00:11:30,000
然後你放入 s3

478
00:11:28,720 --> 00:11:30,000
 and then you put s3

479
00:11:30,000 --> 00:11:35,200
就是從這裡出來的這個，還有 d2 對吧

480
00:11:30,000 --> 00:11:35,200
 which comes out of here this one along with d2 right

481
00:11:35,200 --> 00:11:40,240
d d1 s3 對不起 d1 就在那裡 s3

482
00:11:35,200 --> 00:11:40,240
 d d1 s3 sorry d1 right there s3

483
00:11:40,240 --> 00:11:42,320
然後來到 d2 s2

484
00:11:40,240 --> 00:11:42,320
 and then comes d2 s2

485
00:11:42,320 --> 00:11:43,120
以此類推

486
00:11:42,320 --> 00:11:43,120
 and so on

487
00:11:43,120 --> 00:11:45,120
所以你把這些東西串聯在一起

488
00:11:43,120 --> 00:11:45,120
 so you concatenate these things together

489
00:11:45,120 --> 00:11:45,920
如果我錯了

490
00:11:45,120 --> 00:11:45,920
 if i got it wrong

491
00:11:45,920 --> 00:11:46,640
繼續修正

492
00:11:45,920 --> 00:11:46,640
 go ahead and fix

493
00:11:46,640 --> 00:11:49,839
它，但我們將在下一部分檢查它

494
00:11:46,640 --> 00:11:49,839
 it but we are going to check it out in our next

495
00:11:49,839 --> 00:11:52,160
你知道，在本教程的下一部分

496
00:11:49,839 --> 00:11:52,160
 you know in the next part of this tutorial

497
00:11:52,160 --> 00:11:53,600
我們無論如何都會查看代碼

498
00:11:52,160 --> 00:11:53,600
 where we look at the code anyway

499
00:11:53,600 --> 00:11:56,959
所以如果有任何不匹配的地方，請不要擔心

500
00:11:53,600 --> 00:11:56,959
 so don't worry about any any of these here if there is a mismatch

501
00:11:56,959 --> 00:11:58,240
但我不認為會有任何

502
00:11:56,959 --> 00:11:58,240
 but i don't think there is any

503
00:11:58,240 --> 00:12:00,399
只是先跟你打個預防針

504
00:11:58,240 --> 00:12:00,399
 but just just giving you a heads up

505
00:12:00,399 --> 00:12:01,120
所以最終

506
00:12:00,399 --> 00:12:01,120
 so finally

507
00:12:01,120 --> 00:12:03,680
我的輸出是什麼？我的輸出是一個卷積

508
00:12:01,120 --> 00:12:03,680
 what is my output my output is a convolution

509
00:12:03,680 --> 00:12:07,200
2D 操作，這是到目前為止的輸出，我們完成了

510
00:12:03,680 --> 00:12:07,200
 2d operation this is the output up to this point we are done

511
00:12:07,200 --> 00:12:13,360
這最終的輸出是一個 2D 操作，使用逐一核

512
00:12:07,200 --> 00:12:13,360
 this final output is a con 2d operation with one by one kernel

513
00:12:13,360 --> 00:12:20,000
和激活函數 sigmoid，對吧？這在這個例子中是一個二元的

514
00:12:13,360 --> 00:12:20,000
 and activation sigmoid right this is in this example this is a binary

515
00:12:20,000 --> 00:12:21,440
語義分割

516
00:12:20,000 --> 00:12:21,440
 semantic segmentation

517
00:12:21,440 --> 00:12:22,240
所以輸出

518
00:12:21,440 --> 00:12:22,240
 so the output

519
00:12:22,240 --> 00:12:27,519
所以我將始終使用激活函數 sigmoid，請記住多類別分類

520
00:12:22,240 --> 00:12:27,519
 so i'm going to use activation sigmoid always remember multi-class classification

521
00:12:27,519 --> 00:12:29,920
軟最大激活

522
00:12:27,519 --> 00:12:29,920
 soft max activation

523
00:12:29,920 --> 00:12:31,519
二元分類

524
00:12:29,920 --> 00:12:31,519
 binary classification

525
00:12:31,519 --> 00:12:33,120
sigmoid 激活

526
00:12:31,519 --> 00:12:33,120
 sigmoid activation

527
00:12:33,120 --> 00:12:35,200
但這是語意分割

528
00:12:33,120 --> 00:12:35,200
 but this is semantic segmentation

529
00:12:35,200 --> 00:12:40,079
我在說什麼，語意分割與分類是相同的

530
00:12:35,200 --> 00:12:40,079
 what am i talking about semantic segmentation is same as classification

531
00:12:40,079 --> 00:12:43,600
除非你在對每個像素進行分類，而不是整個圖像

532
00:12:40,079 --> 00:12:43,600
 except you're classifying every pixel instead of the entire image

533
00:12:43,600 --> 00:12:45,760
所以適用相同的規則

534
00:12:43,600 --> 00:12:45,760
 so the same rules apply

535
00:12:45,760 --> 00:12:46,720
好的

536
00:12:45,760 --> 00:12:46,720
 okay

537
00:12:46,720 --> 00:12:48,800
所以那就是你所在的位置

538
00:12:46,720 --> 00:12:48,800
 so that's where that's where you are

539
00:12:48,800 --> 00:12:50,399
所以讓我們跳到代碼部分

540
00:12:48,800 --> 00:12:50,399
 so let's jump to the code

541
00:12:50,399 --> 00:12:55,040
並查看我們是否能學到更多

542
00:12:50,399 --> 00:12:55,040
 and see if we can learn even more

543
00:12:55,040 --> 00:12:55,600
好的

544
00:12:55,040 --> 00:12:55,600
 okay

545
00:12:55,600 --> 00:12:57,120
所以完全相同的事情

546
00:12:55,600 --> 00:12:57,120
 so exactly the same thing

547
00:12:57,120 --> 00:13:01,600
現在我正在匯入庫，讓我們繼續連接

548
00:12:57,120 --> 00:13:01,600
 now i'm importing the libraries let's go ahead and connect

549
00:13:01,600 --> 00:13:04,240
首先

550
00:13:01,600 --> 00:13:04,240
 first of all

551
00:13:04,240 --> 00:13:07,920
讓我們檢查執行時間

552
00:13:04,240 --> 00:13:07,920
 and let's check the runtime

553
00:13:07,920 --> 00:13:10,720
更改運行時類型，我不使用 GPU

554
00:13:07,920 --> 00:13:10,720
 change runtime type i'm not using gpu

555
00:13:10,720 --> 00:13:14,000
因為在這裡我們不需要 GPU，我們只是建立一個模型

556
00:13:10,720 --> 00:13:14,000
 because you don't need gpu here we are just building a model

557
00:13:14,000 --> 00:13:16,880
好的，我們不會使用 GPU

558
00:13:14,000 --> 00:13:16,880
 okay we are not going to use gpu

559
00:13:16,880 --> 00:13:17,200
好的

560
00:13:16,880 --> 00:13:17,200
 okay

561
00:13:17,200 --> 00:13:23,200
從 keras.layers 匯入 input、Convolution2D、MaxPooling2D

562
00:13:17,200 --> 00:13:23,200
 so from keras dot layers i'm going to import the input con 2d max pooling 2d

563
00:13:23,200 --> 00:13:24,399
如果你想使用上採樣

564
00:13:23,200 --> 00:13:24,399
 if you want to use up sampling

565
00:13:24,399 --> 00:13:27,040
你可以使用它，但我將使用 Conv2DTranspose

566
00:13:24,399 --> 00:13:27,040
 go ahead and use it but i'm going to use contoury transpose

567
00:13:27,040 --> 00:13:28,399
正如我之前展示的

568
00:13:27,040 --> 00:13:28,399
 as i already showed you

569
00:13:28,399 --> 00:13:29,920
然後你可以添加中斷

570
00:13:28,399 --> 00:13:29,920
 and then you can add dropouts

571
00:13:29,920 --> 00:13:30,480
及其他

572
00:13:29,920 --> 00:13:30,480
 and others

573
00:13:30,480 --> 00:13:31,200
如果你想

574
00:13:30,480 --> 00:13:31,200
 if you want

575
00:13:31,200 --> 00:13:35,920
那麼我們再次進行函式庫的匯入吧，這對你來說應該不會是新鮮事

576
00:13:31,200 --> 00:13:35,920
 so let's go ahead and import our libraries again this should be nothing new to you

577
00:13:35,920 --> 00:13:37,760
現在讓我們來定義卷積

578
00:13:35,920 --> 00:13:37,760
 and now let's define the convolution

579
00:13:37,760 --> 00:13:41,680
區塊，我不想重複我談過的所有內容，這實際上是

580
00:13:37,760 --> 00:13:41,680
 block again i don't want to repeat everything that i talked about this is literally

581
00:13:41,680 --> 00:13:44,399
我們之前看到的，卷積區塊

582
00:13:41,680 --> 00:13:44,399
 what we saw earlier the convolution block

583
00:13:44,399 --> 00:13:45,920
演示中的 OK

584
00:13:44,399 --> 00:13:45,920
 okay in the presentation

585
00:13:45,920 --> 00:13:47,680
現在編碼器區塊什麼都沒有

586
00:13:45,920 --> 00:13:47,680
 now encoder block is nothing

587
00:13:47,680 --> 00:13:51,040
只有具有最大池化的卷積區塊

588
00:13:47,680 --> 00:13:51,040
 but convolution block with max pooling

589
00:13:51,040 --> 00:13:53,839
然後我們會給出卷積區塊的輸出

590
00:13:51,040 --> 00:13:53,839
 and then we give both the output of a convolution block

591
00:13:53,839 --> 00:13:57,199
和最大池化，我們將返回這兩個

592
00:13:53,839 --> 00:13:57,199
 and the max pooling we we are going to return those two

593
00:13:57,199 --> 00:14:03,040
而這些中的一個將作為下一步的輸入

594
00:13:57,199 --> 00:14:03,040
 and one of these like that one is going in as input for the next

595
00:14:03,040 --> 00:14:03,920
解碼器區塊

596
00:14:03,040 --> 00:14:03,920
 decoder block

597
00:14:03,920 --> 00:14:06,000
所以我們來定義解碼器

598
00:14:03,920 --> 00:14:06,000
 so let's go ahead and define the decoder

599
00:14:06,000 --> 00:14:09,839
這就是我們構建單元的方式

600
00:14:06,000 --> 00:14:09,839
 and this is the way we build our unit

601
00:14:09,839 --> 00:14:14,000
我早些時候在這段視頻錄製中添加了這個功能

602
00:14:09,839 --> 00:14:14,000
 and i added this function earlier to this recording of this video

603
00:14:14,000 --> 00:14:15,040
哪裡

604
00:14:14,000 --> 00:14:15,040
 where

605
00:14:15,040 --> 00:14:16,959
我說好，如果我的類別數量

606
00:14:15,040 --> 00:14:16,959
 i said okay if my number of classes

607
00:14:16,959 --> 00:14:20,639
因為這是其中的一個輸入，如果我的類別數量等於 1

608
00:14:16,959 --> 00:14:20,639
 because that's one of the inputs right if my number of classes equal to 1

609
00:14:20,639 --> 00:14:26,320
這意味著它是一個二元分類，記住二元分類意味著你只有一個類別

610
00:14:20,639 --> 00:14:26,320
 which means it's a binary classification remember binary classification means you have one class

611
00:14:26,320 --> 00:14:27,360
和

612
00:14:26,320 --> 00:14:27,360
 and

613
00:14:27,360 --> 00:14:30,959
問題被定義為背景為零

614
00:14:27,360 --> 00:14:30,959
 and the problem is defined as it's either background like zero

615
00:14:30,959 --> 00:14:32,240
或者一

616
00:14:30,959 --> 00:14:32,240
 or one

617
00:14:32,240 --> 00:14:33,760
這是二進位的

618
00:14:32,240 --> 00:14:33,760
 that's binary

619
00:14:33,760 --> 00:14:35,120
所以你有一個黑暗的背景

620
00:14:33,760 --> 00:14:35,120
 so you have a dark background

621
00:14:35,120 --> 00:14:37,920
而你的物體是明亮的

622
00:14:35,120 --> 00:14:37,920
 and you have like your objects in bright

623
00:14:37,920 --> 00:14:39,440
所以這是二元分類

624
00:14:37,920 --> 00:14:39,440
 so this is binary classification

625
00:14:39,440 --> 00:14:42,720
所以這是零或一，所以如果是這種情況，使用 sigmoid

626
00:14:39,440 --> 00:14:42,720
 so it's either zero or one so if that's the case use sigmoid

627
00:14:42,720 --> 00:14:45,360
否則使用激活函數如 soft max

628
00:14:42,720 --> 00:14:45,360
 otherwise use activation as soft max

629
00:14:45,360 --> 00:14:47,120
所以我們可以在任何情況下調用這個

630
00:14:45,360 --> 00:14:47,120
 so we can call this no matter

631
00:14:47,120 --> 00:14:50,320
無論你知道多少

632
00:14:47,120 --> 00:14:50,320
 how many you know no matter

633
00:14:50,320 --> 00:14:52,320
你要分割的類別數量

634
00:14:50,320 --> 00:14:52,320
 how many classes you're going to segment

635
00:14:52,320 --> 00:14:52,639
好的

636
00:14:52,320 --> 00:14:52,639
 okay

637
00:14:52,639 --> 00:14:54,320
那麼我們就開始吧

638
00:14:52,639 --> 00:14:54,320
 so let's go ahead and do that

639
00:14:54,320 --> 00:14:58,959
那麼讓我們建立我們的單元，假設我的輸入形狀不僅僅是灰階

640
00:14:54,320 --> 00:14:58,959
 and let's build our unit let's say my input shape is not just a grayscale

641
00:14:58,959 --> 00:15:02,000
而是一張顏色圖片 256x256x3

642
00:14:58,959 --> 00:15:02,000
 but a color image 256 by 256x3

643
00:15:02,000 --> 00:15:07,600
而且我的類別數量等於 1。繼續並打印摘要

644
00:15:02,000 --> 00:15:07,600
 and my number of classes equals to 1. go ahead and print the summary

645
00:15:07,600 --> 00:15:10,480
所以這是摘要，讓我們往下滾動

646
00:15:07,600 --> 00:15:10,480
 so here is the summary let's scroll down

647
00:15:10,480 --> 00:15:12,560
然後從最上面開始

648
00:15:10,480 --> 00:15:12,560
 and start from the top

649
00:15:12,560 --> 00:15:16,639
來了，它以 256 256 3 作為你的輸入層開始

650
00:15:12,560 --> 00:15:16,639
 there you go it starts with 256 256 3 as your input layer

651
00:15:16,639 --> 00:15:19,600
然後 64 64 右邊

652
00:15:16,639 --> 00:15:19,600
 and then 64 64 right

653
00:15:19,600 --> 00:15:22,320
一直往下到 1024

654
00:15:19,600 --> 00:15:22,320
 and so on all the way down to 1024

655
00:15:22,320 --> 00:15:25,680
然後一直回到

656
00:15:22,320 --> 00:15:25,680
 and then all the way back to

657
00:15:25,680 --> 00:15:31,440
這是二元的，再次是二元分類

658
00:15:25,680 --> 00:15:31,440
 256 256 1 y1 this is a binary again binary classification

659
00:15:31,440 --> 00:15:32,720
所以你要麼有 0

660
00:15:31,440 --> 00:15:32,720
 so you either have 0

661
00:15:32,720 --> 00:15:33,440
或 1。

662
00:15:32,720 --> 00:15:33,440
 or 1.

663
00:15:33,440 --> 00:15:35,759
現在我們將這個改為多類別

664
00:15:33,440 --> 00:15:35,759
 now let's change this to a multi-class

665
00:15:35,759 --> 00:15:37,600
我們如何將這個改為多類別

666
00:15:35,759 --> 00:15:37,600
 how do we change this to multi-class

667
00:15:37,600 --> 00:15:39,279
所以對於多類別

668
00:15:37,600 --> 00:15:39,279
 so for multi-class

669
00:15:39,279 --> 00:15:43,759
儘管我的輸入影像仍然是彩色的，您可以將其更改為灰階

670
00:15:39,279 --> 00:15:43,759
 still my input images are color here you can change that to grayscale

671
00:15:43,759 --> 00:15:48,240
如果是灰階，您的輸入將是 256 到 56 1 對吧

672
00:15:43,759 --> 00:15:48,240
 if that is grayscale your input would be 256 to 56 1 right

673
00:15:48,240 --> 00:15:50,560
但讓我們將其更改為彩色

674
00:15:48,240 --> 00:15:50,560
 but let's change that to color that

675
00:15:50,560 --> 00:15:52,959
和類別數量，假設我有四個類別

676
00:15:50,560 --> 00:15:52,959
 and number of classes let's say i have four classes

677
00:15:52,959 --> 00:15:58,560
四個不同的區域，我想在語義分割中識別，輸入四

678
00:15:52,959 --> 00:15:58,560
 four different regions that i want to identify in my semantic segmentation just type four

679
00:15:58,560 --> 00:16:01,920
你會看到輸出層，它必須顯示四個

680
00:15:58,560 --> 00:16:01,920
 you see the output layer it has to come up with four

681
00:16:01,920 --> 00:16:02,399
好的

682
00:16:01,920 --> 00:16:02,399
 yeah

683
00:16:02,399 --> 00:16:03,839
那我們就往下走

684
00:16:02,399 --> 00:16:03,839
 so let's go down

685
00:16:03,839 --> 00:16:07,519
然後你就這樣完成了 256 到 56 4。

686
00:16:03,839 --> 00:16:07,519
 and there you go 256 to 56 4.

687
00:16:07,519 --> 00:16:08,480
好的

688
00:16:07,519 --> 00:16:08,480
 okay

689
00:16:08,480 --> 00:16:11,680
然後一旦你有了模型，你只需要編譯

690
00:16:08,480 --> 00:16:11,680
 and then once you have your model you just compile

691
00:16:11,680 --> 00:16:12,320
在這裡

692
00:16:11,680 --> 00:16:12,320
 right here

693
00:16:12,320 --> 00:16:18,000
我是否印出了啟動碼只是為了展示給你

694
00:16:12,320 --> 00:16:18,000
 and did i print the activation just to show you

695
00:16:18,000 --> 00:16:20,320
抱歉，我們回到上面去

696
00:16:18,000 --> 00:16:20,320
 sorry about this let's go back up

697
00:16:20,320 --> 00:16:21,680
是的，你可以列印啟用

698
00:16:20,320 --> 00:16:21,680
 yeah you can print the activation

699
00:16:21,680 --> 00:16:24,160
在那裡查看它是否真的使用了 soft max

700
00:16:21,680 --> 00:16:24,160
 right there to see if it is really using soft max

701
00:16:24,160 --> 00:16:24,720
或 sigmoid

702
00:16:24,160 --> 00:16:24,720
 or sigmoid

703
00:16:24,720 --> 00:16:27,440
我是說這是相當簡單的，它應該使用 softmax

704
00:16:24,720 --> 00:16:27,440
 i mean this is pretty straight forward it should be using soft max

705
00:16:27,440 --> 00:16:30,399
因為這是多於一個的類別數

706
00:16:27,440 --> 00:16:30,399
 because this is a number of classes is more than one

707
00:16:30,399 --> 00:16:31,440
好的

708
00:16:30,399 --> 00:16:31,440
 okay

709
00:16:31,440 --> 00:16:34,240
所以這是讓我們往下看

710
00:16:31,440 --> 00:16:34,240
 so this is let's go down

711
00:16:34,240 --> 00:16:38,240
一旦你定義了模型，接著你需要編譯它對吧

712
00:16:34,240 --> 00:16:38,240
 and once you have the model defined then you need to compile it right

713
00:16:38,240 --> 00:16:42,880
因此，對於這個模型的編譯，你可以使用隨機梯度下降法

714
00:16:38,240 --> 00:16:42,880
 so for compilation of this model you can use a stochastic gradient descent

715
00:16:42,880 --> 00:16:47,759
或者是基於隨機梯度下降法的一些東西

716
00:16:42,880 --> 00:16:47,759
 or something that's based on stochastic gradient descent type of

717
00:16:47,759 --> 00:16:48,560
優化器

718
00:16:47,759 --> 00:16:48,560
 optimizer

719
00:16:48,560 --> 00:16:51,199
所以在這個例子中，原子

720
00:16:48,560 --> 00:16:51,199
 so in this example atom

721
00:16:51,199 --> 00:16:52,639
和損失函數

722
00:16:51,199 --> 00:16:52,639
 and loss function

723
00:16:52,639 --> 00:16:54,720
在這個例子中，二元交叉熵

724
00:16:52,639 --> 00:16:54,720
 so in this example binary cross entropy

725
00:16:54,720 --> 00:17:00,079
如果是多類別的話使用錯誤，對於多類別應該使用

726
00:16:54,720 --> 00:17:00,079
 which is the wrong one to use if it is multi-class for multi-class it should be

727
00:17:00,079 --> 00:17:01,199
多類別交叉熵

728
00:17:00,079 --> 00:17:01,199
 multi-cross entropy

729
00:17:01,199 --> 00:17:04,319
或者你知道分類交叉熵不是二元的

730
00:17:01,199 --> 00:17:04,319
 or you know categorical cross entropy not binary

731
00:17:04,319 --> 00:17:07,199
好的，確保你使用正確的損失函數

732
00:17:04,319 --> 00:17:07,199
 okay make sure you use the right loss functions

733
00:17:07,199 --> 00:17:08,559
然後是指標

734
00:17:07,199 --> 00:17:08,559
 and then for metrics

735
00:17:08,559 --> 00:17:12,720
我現在會使用準確率，順便提一下我應該已經提過了

736
00:17:08,559 --> 00:17:12,720
 i'm going to use accuracy right now by the way i should already mention that

737
00:17:12,720 --> 00:17:18,640
使用準確度作為語意分割的衡量指標是不好的

738
00:17:12,720 --> 00:17:18,640
 using an accuracy as a metric for semantic segmentation is not good

739
00:17:18,640 --> 00:17:22,880
嗯，這不會給你結果，它會

740
00:17:18,640 --> 00:17:22,880
 well it's not going to give you it it is going to

741
00:17:22,880 --> 00:17:25,280
你知道，它會收斂，不像

742
00:17:22,880 --> 00:17:25,280
 you know it's going to converge it's not like

743
00:17:25,280 --> 00:17:30,960
但問題是達到 95%、98%、99% 的準確度很容易

744
00:17:25,280 --> 00:17:30,960
 but the problem is it's easy to get 95 98 99 accuracy

745
00:17:30,960 --> 00:17:34,880
但結果仍然可能非常糟糕，那是因為準確度

746
00:17:30,960 --> 00:17:34,880
 but still get very horrible results that's because accuracy

747
00:17:34,880 --> 00:17:36,640
包含背景

748
00:17:34,880 --> 00:17:36,640
 includes the background

749
00:17:36,640 --> 00:17:41,600
如果背景很複雜而物體很少，那麼你可以達到 98%的準確度

750
00:17:36,640 --> 00:17:41,600
 if you have a lot of background very little of objects then you do get 98 accuracy

751
00:17:41,600 --> 00:17:43,679
那麼在這種情況下，最佳的指標是什麼呢？

752
00:17:41,600 --> 00:17:43,679
 right so what is the best metric in that case

753
00:17:43,679 --> 00:17:46,080
在這種情況下，最佳的指標會是某種被稱為

754
00:17:43,679 --> 00:17:46,080
 in that case the best metric would be something called

755
00:17:46,080 --> 00:17:49,200
交集聯合指標 IOU

756
00:17:46,080 --> 00:17:49,200
 intersection over union iou

757
00:17:49,200 --> 00:17:50,960
好的，這是最佳的指標

758
00:17:49,200 --> 00:17:50,960
 okay that's the best metric

759
00:17:50,960 --> 00:17:56,320
我們會在接下來的教程中再次提到這個主題

760
00:17:50,960 --> 00:17:56,320
 and we will touch about that topic again in the upcoming tutorials

761
00:17:56,320 --> 00:17:58,880
但現在讓我先停在這裡

762
00:17:56,320 --> 00:17:58,880
 but for now let me go ahead and stop here

763
00:17:58,880 --> 00:18:00,400
因為

764
00:17:58,880 --> 00:18:00,400
 because

765
00:18:00,400 --> 00:18:04,080
現在我們有一個運作良好的模型

766
00:18:00,400 --> 00:18:04,080
 now we have a model that works fine

767
00:18:04,080 --> 00:18:06,720
我們有這個對於二元分類有效的模型

768
00:18:04,080 --> 00:18:06,720
 we have this model that works fine for binary

769
00:18:06,720 --> 00:18:07,679
或多類別

770
00:18:06,720 --> 00:18:07,679
 or multi-class

771
00:18:07,679 --> 00:18:10,080
那麼我們在下一個影片中開始吧

772
00:18:07,679 --> 00:18:10,080
 so let's start in the next video

773
00:18:10,080 --> 00:18:12,000
我們來談談二元分類

774
00:18:10,080 --> 00:18:12,000
 let's talk about binary classification

775
00:18:12,000 --> 00:18:14,799
讓我們看看如何將這應用到二元分類問題中

776
00:18:12,000 --> 00:18:14,799
 let's see how we can apply this to a binary classification problem

777
00:18:14,799 --> 00:18:18,160
然後我們接下來來看看多類別分類

778
00:18:14,799 --> 00:18:18,160
 and the one after that let's look at multi-class classification

779
00:18:18,160 --> 00:18:20,960
然後稍後我們會看看 3D 數據集

780
00:18:18,160 --> 00:18:20,960
 and then later on we'll look at 3d data sets

781
00:18:20,960 --> 00:18:24,400
所以請繼續關注，訂閱這個頻道

782
00:18:20,960 --> 00:18:24,400
 and so on okay so please stay tuned subscribe to this channel

783
00:18:24,400 --> 00:18:25,440
讓我們在下個影片見面

784
00:18:24,400 --> 00:18:25,440
 and let's meet in the next video

