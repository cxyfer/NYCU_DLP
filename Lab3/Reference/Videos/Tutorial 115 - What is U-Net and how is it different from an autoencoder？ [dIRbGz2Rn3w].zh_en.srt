1
00:00:00,799 --> 00:00:05,920
嗨大家好，歡迎回到圖像處理的入門 Python 教學

2
00:00:00,799 --> 00:00:05,920
hi everyone welcome back to the introductory python tutorials for image processing

3
00:00:05,920 --> 00:00:09,200
在最後幾個視頻中，我們研究了自動編碼器

4
00:00:05,920 --> 00:00:09,200
 in the last couple of videos we looked at auto encoders

5
00:00:09,200 --> 00:00:12,240
再來一個快速總結，自動編碼器

6
00:00:09,200 --> 00:00:12,240
 and again a quick summary auto encoders

7
00:00:12,240 --> 00:00:14,639
根據定義，它們接受一個輸入

8
00:00:12,240 --> 00:00:14,639
 by definition they take an input

9
00:00:14,639 --> 00:00:16,720
他們嘗試重建這些輸入

10
00:00:14,639 --> 00:00:16,720
 and they try to reconstruct that input

11
00:00:16,720 --> 00:00:22,080
我們正試圖通過提供輸入來欺騙這些自動編碼器

12
00:00:16,720 --> 00:00:22,080
 and we are trying to trick these auto encoders by providing an input

13
00:00:22,080 --> 00:00:24,320
比如說，一張圖片

14
00:00:22,080 --> 00:00:24,320
 you know like an image for example

15
00:00:24,320 --> 00:00:26,960
以及預期輸出會有所不同

16
00:00:24,320 --> 00:00:26,960
 and the expected output to be something else

17
00:00:26,960 --> 00:00:30,480
通過這樣做，我們嘗試使用自動編碼器

18
00:00:26,960 --> 00:00:30,480
 and by doing that we're trying to use auto encoders

19
00:00:30,480 --> 00:00:31,840
或者你知道的

20
00:00:30,480 --> 00:00:31,840
 or you know for

21
00:00:31,840 --> 00:00:35,520
或為特定應用如影像著色自訂自動編碼器

22
00:00:31,840 --> 00:00:35,520
 or customize auto encoders for certain applications like image colorization

23
00:00:35,520 --> 00:00:36,480
或去噪

24
00:00:35,520 --> 00:00:36,480
 or denoising

25
00:00:36,480 --> 00:00:41,440
我們目前的重點是看看這是否可以用於語意分割

26
00:00:36,480 --> 00:00:41,440
 and our focus right now is to see if that can be used for semantic segmentation

27
00:00:41,440 --> 00:00:44,399
在上一個視頻中，我們意識到也許不是

28
00:00:41,440 --> 00:00:44,399
 and in the last video we realized that maybe not

29
00:00:44,399 --> 00:00:49,520
我的意思是，結果在初看時看起來很好

30
00:00:44,399 --> 00:00:49,520
 i mean it the results look good on first you know on first look

31
00:00:49,520 --> 00:00:52,960
但存在空間信息的丟失

32
00:00:49,520 --> 00:00:52,960
 but there is a loss of spatial information

33
00:00:52,960 --> 00:00:55,440
這對於語意分割來說非常重要

34
00:00:52,960 --> 00:00:55,440
 which is very important for semantic segmentation

35
00:00:55,440 --> 00:00:58,160
因為畢竟我們正在嘗試分類

36
00:00:55,440 --> 00:00:58,160
 because after all we are trying to classify

37
00:00:58,160 --> 00:00:59,760
我們影像中的每一個像素

38
00:00:58,160 --> 00:00:59,760
 every pixel in our image

39
00:00:59,760 --> 00:01:02,640
那麼在這段影片中，我們來學習一下單位

40
00:00:59,760 --> 00:01:02,640
 so in this video let's learn about units

41
00:01:02,640 --> 00:01:04,640
以及它們如何與自動編碼器不同

42
00:01:02,640 --> 00:01:04,640
 and how they are different from an auto encoder

43
00:01:04,640 --> 00:01:05,438
或

44
00:01:04,640 --> 00:01:05,438
 or

45
00:01:05,438 --> 00:01:08,479
或許我應該將它表述為它們如何與自動編碼器相似

46
00:01:05,438 --> 00:01:08,479
 maybe i should have phrased it as how they are similar to autoencoder

47
00:01:08,479 --> 00:01:10,320
自編碼器的限制是什麼

48
00:01:08,479 --> 00:01:10,320
 like what is the limitation of autoencoder

49
00:01:10,320 --> 00:01:12,479
單位如何解決這一限制

50
00:01:10,320 --> 00:01:12,479
 and how do units fix that limitation

51
00:01:12,479 --> 00:01:14,880
讓我們先了解一下這一點，所以首先讓我們

52
00:01:12,479 --> 00:01:14,880
 let's understand that so first of all let's

53
00:01:14,880 --> 00:01:17,280
快速看一下我們的自動編碼器

54
00:01:14,880 --> 00:01:17,280
 have a quick look at our auto encoder

55
00:01:17,280 --> 00:01:20,159
再次顯示一個大圖像

56
00:01:17,280 --> 00:01:20,159
 again a large image

57
00:01:20,159 --> 00:01:22,400
漸漸變小

58
00:01:20,159 --> 00:01:22,400
 progressively goes down in size

59
00:01:22,400 --> 00:01:25,200
但接著特徵數量增加

60
00:01:22,400 --> 00:01:25,200
 but then goes up in number of features

61
00:01:25,200 --> 00:01:27,439
是的，這裡 128 256 512

62
00:01:25,200 --> 00:01:27,439
 yeah here 128 256 512

63
00:01:27,439 --> 00:01:28,560
以此類推

64
00:01:27,439 --> 00:01:28,560
 and so on

65
00:01:28,560 --> 00:01:35,520
從這個瓶頸開始，圖像將恢復到原始大小

66
00:01:28,560 --> 00:01:35,520
 and from from from this bottleneck it's going back up to the image's original size

67
00:01:35,520 --> 00:01:38,880
如果你提供一張這樣的圖片作為輸入

68
00:01:35,520 --> 00:01:38,880
 so if you provide it with a image like this as input

69
00:01:38,880 --> 00:01:43,040
如果你的預期輸出是相同的，那麼它會將輸入重新構建回來

70
00:01:38,880 --> 00:01:43,040
 and if your expected output is the same then it reconstructs the input back

71
00:01:43,040 --> 00:01:43,520
但

72
00:01:43,040 --> 00:01:43,520
 but

73
00:01:43,520 --> 00:01:49,920
如果你提供的預期輸出是這樣，那麼它應該會重建出類似這樣的東西

74
00:01:43,520 --> 00:01:49,920
 if you provide your expected output as this then it is expected to reconstruct something of this sort

75
00:01:49,920 --> 00:01:54,000
但這就是我們從上一段視頻看到的內容

76
00:01:49,920 --> 00:01:54,000
 but then this is what we saw that from the last video right

77
00:01:54,000 --> 00:01:55,680
所以這是我們所期望的

78
00:01:54,000 --> 00:01:55,680
 so this is what we expect

79
00:01:55,680 --> 00:01:56,719
而這是我們看到的

80
00:01:55,680 --> 00:01:56,719
 and this is what we saw

81
00:01:56,719 --> 00:01:57,840
看起來很棒

82
00:01:56,719 --> 00:01:57,840
 which looks great

83
00:01:57,840 --> 00:01:59,840
初看時顏色都正確

84
00:01:57,840 --> 00:01:59,840
 on first look it got the colors right

85
00:01:59,840 --> 00:02:01,600
它把一切都做對了

86
00:01:59,840 --> 00:02:01,600
 it got everything right it got

87
00:02:01,600 --> 00:02:04,079
大部分的空間位置正確，除了

88
00:02:01,600 --> 00:02:04,079
 most of the spatial locations right except

89
00:02:04,079 --> 00:02:05,280
這不是非常準確

90
00:02:04,079 --> 00:02:05,280
 it's not very accurate

91
00:02:05,280 --> 00:02:06,640
當涉及到這些空間時

92
00:02:05,280 --> 00:02:06,640
 when it comes to these spatial

93
00:02:06,640 --> 00:02:07,600
你會看到一切看起來

94
00:02:06,640 --> 00:02:07,600
 you see everything looks

95
00:02:07,600 --> 00:02:08,878
有點模糊

96
00:02:07,600 --> 00:02:08,878
 like a bit blurred

97
00:02:08,878 --> 00:02:10,479
它幾乎看起來像

98
00:02:08,878 --> 00:02:10,479
 it's almost looks like

99
00:02:10,479 --> 00:02:14,239
這是上述圖像的高斯濾波版本

100
00:02:10,479 --> 00:02:14,239
 this is gaussian filtered version of this above image

101
00:02:14,239 --> 00:02:17,360
這是模糊的圓形物體，再次發生

102
00:02:14,239 --> 00:02:17,360
 this is fuzzy rounded objects that is again happening

103
00:02:17,360 --> 00:02:24,080
因為當你到達這裡時，它失去了所有的空間信息

104
00:02:17,360 --> 00:02:24,080
 because by the time you get down here it lost all of its spatial information

105
00:02:24,080 --> 00:02:29,760
在這裡，你在第一次對話中擁有非常好的空間信息

106
00:02:24,080 --> 00:02:29,760
 that that you have from here at convo one you have very good spatial information right contu

107
00:02:29,760 --> 00:02:30,959
稍微具體一點

108
00:02:29,760 --> 00:02:30,959
 a little bit concrete

109
00:02:30,959 --> 00:02:33,440
但是到 con5 你失去了那個信息

110
00:02:30,959 --> 00:02:33,440
 but then up to con5 you lost that information

111
00:02:33,440 --> 00:02:36,959
那麼我們如何獲得這些，我們如何保留這些特殊信息

112
00:02:33,440 --> 00:02:36,959
 so how do we gain that how do we retain this special information

113
00:02:36,959 --> 00:02:40,239
這就是單元再次解決的問題，正如你可能已經意識到的

114
00:02:36,959 --> 00:02:40,239
 this is what unit solves again as you probably realized

115
00:02:40,239 --> 00:02:44,720
所以讓我們以一種簡單的抽象方式來看看自動編碼器，現在不要去看

116
00:02:40,239 --> 00:02:44,720
 so let's look at the auto encoder in a nice abstract way right not look at

117
00:02:44,720 --> 00:02:47,280
讓這變得像這個自動編碼器一樣複雜

118
00:02:44,720 --> 00:02:47,280
 make this as complicated as this autoencoder

119
00:02:47,280 --> 00:02:49,920
再次是任何從大尺寸變小的東西

120
00:02:47,280 --> 00:02:49,920
 again is anything that goes from a large size small

121
00:02:49,920 --> 00:02:53,120
然後在卷積層中再次變大

122
00:02:49,920 --> 00:02:53,120
 and then goes back up in in convolutional layers

123
00:02:53,120 --> 00:02:54,080
所以

124
00:02:53,120 --> 00:02:54,080
 so

125
00:02:54,080 --> 00:02:56,560
我們有這個編碼器部分，剩下的就是解碼器

126
00:02:54,080 --> 00:02:56,560
 we have this encoder part and the remaining is the decoder

127
00:02:56,560 --> 00:02:59,440
對，如何有效保留空間資訊

128
00:02:56,560 --> 00:02:59,440
 right so how to retain spatial information well

129
00:02:59,440 --> 00:03:02,879
如果我們取

130
00:02:59,440 --> 00:03:02,879
 what if we take

131
00:03:02,879 --> 00:03:08,400
將這裡的空間資訊添加到解碼器層的下一部分

132
00:03:02,879 --> 00:03:08,400
 add the spatial information from here to the next part to the decoder layers

133
00:03:08,400 --> 00:03:12,319
如果我們能夠將編碼器的空間資訊添加到解碼器的右側

134
00:03:08,400 --> 00:03:12,319
 what if we can take encoder spatial information add to decoder right

135
00:03:12,319 --> 00:03:13,200
所以這正是

136
00:03:12,319 --> 00:03:13,200
 so this is exactly

137
00:03:13,200 --> 00:03:15,680
我所說的

138
00:03:13,200 --> 00:03:15,680
 what i'm talking about

139
00:03:15,680 --> 00:03:17,840
獲取空間資訊

140
00:03:15,680 --> 00:03:17,840
 take the spatial information

141
00:03:17,840 --> 00:03:21,280
將其添加到解碼器中的功能資訊

142
00:03:17,840 --> 00:03:21,280
 add it to the feature information that you have in the decoder

143
00:03:21,280 --> 00:03:22,879
當我說添加空間資訊時

144
00:03:21,280 --> 00:03:22,879
 when i say add spatial information

145
00:03:22,879 --> 00:03:24,879
我的意思是取出這些功能

146
00:03:22,879 --> 00:03:24,879
 i mean the take the features

147
00:03:24,879 --> 00:03:26,319
從編碼器

148
00:03:24,879 --> 00:03:26,319
 from the encoder

149
00:03:26,319 --> 00:03:29,360
把它加到解碼器，這正是

150
00:03:26,319 --> 00:03:29,360
 add it to the decoder this is exactly

151
00:03:29,360 --> 00:03:34,000
現在讓我們做這些箭頭

152
00:03:29,360 --> 00:03:34,000
 now let's let's make these arrows

153
00:03:34,000 --> 00:03:36,319
這些箭頭是直的

154
00:03:34,000 --> 00:03:36,319
 these arrows straight

155
00:03:36,319 --> 00:03:39,519
這就是我現在試圖以圖形方式做的全部

156
00:03:36,319 --> 00:03:39,519
 that's all i'm trying to do right now in a graphical way

157
00:03:39,519 --> 00:03:42,239
如果我把這些弄直會發生什麼

158
00:03:39,519 --> 00:03:42,239
 how do i what happens if i make these straight

159
00:03:42,239 --> 00:03:43,280
我要彎曲

160
00:03:42,239 --> 00:03:43,280
 i'm going to bend

161
00:03:43,280 --> 00:03:45,680
將它彎成 U 形

162
00:03:43,280 --> 00:03:45,680
 this in a u shape

163
00:03:45,680 --> 00:03:46,720
是的，這正是

164
00:03:45,680 --> 00:03:46,720
 yeah that's exactly

165
00:03:46,720 --> 00:03:48,080
單位是什麼

166
00:03:46,720 --> 00:03:48,080
 what a unit is

167
00:03:48,080 --> 00:03:54,640
所以我的編碼器仍然在那裡，我只是把這些連接直接連接了

168
00:03:48,080 --> 00:03:54,640
 so my encoder is still right there i just made these connections straight these connections straight

169
00:03:54,640 --> 00:03:58,799
所以這有點彎曲，瓶頸就在這裡

170
00:03:54,640 --> 00:03:58,799
 so this is a bit bent with this bottleneck sitting down here

171
00:03:58,799 --> 00:04:02,640
所以這圖完全一樣，這只是一種不同的表示方式

172
00:03:58,799 --> 00:04:02,640
 so it's exactly the same diagram by the way it's a different representation

173
00:04:02,640 --> 00:04:04,400
所以我可以解釋

174
00:04:02,640 --> 00:04:04,400
 so i can justify

175
00:04:04,400 --> 00:04:06,560
叫它單元

176
00:04:04,400 --> 00:04:06,560
 calling it unit

177
00:04:06,560 --> 00:04:10,640
這部分基本上是我們的編碼器，您可以在這裡看到

178
00:04:06,560 --> 00:04:10,640
 this part is basically our encoder that you see here

179
00:04:10,640 --> 00:04:14,879
這部分基本上是我們的解碼器，唯一的區別是這個

180
00:04:10,640 --> 00:04:14,879
 and this part is basically our decoder the only difference between this

181
00:04:14,879 --> 00:04:18,320
這是這些輸入的串聯

182
00:04:14,879 --> 00:04:18,320
 and this is the concatenation of these input

183
00:04:18,320 --> 00:04:21,839
來自這些層的輸入，就這樣，這就是簡而言之

184
00:04:18,320 --> 00:04:21,839
 inputs from these layers that's it this is in a nutshell

185
00:04:21,839 --> 00:04:25,919
單元是什麼，你可以閱讀論文來獲得更多關於這方面的信息

186
00:04:21,839 --> 00:04:25,919
 what a unit is you can read the paper to get a lot more information about this

187
00:04:25,919 --> 00:04:28,080
這是這篇論文

188
00:04:25,919 --> 00:04:28,080
 and this is the paper

189
00:04:28,080 --> 00:04:32,240
來自 2015 年的生物醫學影像分割的卷積神經網絡

190
00:04:28,080 --> 00:04:32,240
 convolutional networks for biomedical image segmentation from 2015

191
00:04:32,240 --> 00:04:34,720
儘管這是五六年前的

192
00:04:32,240 --> 00:04:34,720
 even though this is from five six years ago

193
00:04:34,720 --> 00:04:37,040
概念仍然

194
00:04:34,720 --> 00:04:37,040
 the the concept still

195
00:04:37,040 --> 00:04:41,919
規則，我應該說這仍然是語義分割的最佳方法

196
00:04:37,040 --> 00:04:41,919
 rules i should say this is still the best way of for semantic segmentation

197
00:04:41,919 --> 00:04:43,600
現在只需了解

198
00:04:41,919 --> 00:04:43,600
 now just to understand

199
00:04:43,600 --> 00:04:46,800
這稍微好一些，這是他們實際發布的原始圖像

200
00:04:43,600 --> 00:04:46,800
 this a bit better this is the original image that they actually published

201
00:04:46,800 --> 00:04:51,360
在他們的論文中，輸入圖像為 572 x 572

202
00:04:46,800 --> 00:04:51,360
 in the in the in their paper with input images 572 by 572

203
00:04:51,360 --> 00:04:56,000
等等，但這不重要，只需更仔細地查看這個表示

204
00:04:51,360 --> 00:04:56,000
 and so on but it doesn't matter just have a closer look in this representation

205
00:04:56,000 --> 00:05:00,960
從輸入來看，你有兩個卷積層，藍色線條，藍色箭頭

206
00:04:56,000 --> 00:05:00,960
 going from the input you have two convolution layers the blue line the blue arrow

207
00:05:00,960 --> 00:05:02,960
代表三乘三的卷積

208
00:05:00,960 --> 00:05:02,960
 represents a three by three convolution

209
00:05:02,960 --> 00:05:05,520
使用 ReLU 激活函數的操作

210
00:05:02,960 --> 00:05:05,520
 operation with a relu activation function

211
00:05:05,520 --> 00:05:06,000
好的

212
00:05:05,520 --> 00:05:06,000
 okay

213
00:05:06,000 --> 00:05:08,960
每條藍線都是一個 2D 卷積

214
00:05:06,000 --> 00:05:08,960
 so each blue line is a con convolution 2d con

215
00:05:08,960 --> 00:05:09,520
或 3D

216
00:05:08,960 --> 00:05:09,520
 or 3d

217
00:05:09,520 --> 00:05:11,360
如果你想將這個擴展到 3D

218
00:05:09,520 --> 00:05:11,360
 if you want to extend this to 3d

219
00:05:11,360 --> 00:05:13,919
但我們就假設這是一個卷積

220
00:05:11,360 --> 00:05:13,919
 but let's just say this is a convolution

221
00:05:13,919 --> 00:05:15,440
隨後是

222
00:05:13,919 --> 00:05:15,440
 followed by

223
00:05:15,440 --> 00:05:18,400
無線電啟用卷積與鐵路啟用

224
00:05:15,440 --> 00:05:18,400
 radio activation convolution with railway activation

225
00:05:18,400 --> 00:05:21,520
在這之後，你將進行最大池化

226
00:05:18,400 --> 00:05:21,520
 after this you're doing max pooling

227
00:05:21,520 --> 00:05:22,639
2 乘 2 最大池化

228
00:05:21,520 --> 00:05:22,639
 2 by 2 max pooling

229
00:05:22,639 --> 00:05:27,120
當你進行 2x2 的最大池化時，輸入圖像的大小會縮小

230
00:05:22,639 --> 00:05:27,120
 what happens when you do max pooling 2x2 the input image size goes down

231
00:05:27,120 --> 00:05:30,240
所以你的輸入圖像不再是 570

232
00:05:27,120 --> 00:05:30,240
 so instead of your input image being 570

233
00:05:30,240 --> 00:05:30,720
或其他什麼

234
00:05:30,240 --> 00:05:30,720
 or something

235
00:05:30,720 --> 00:05:33,440
現在它是 284 乘 284

236
00:05:30,720 --> 00:05:33,440
 now it is 284 by 284 right there

237
00:05:33,440 --> 00:05:34,000
好的

238
00:05:33,440 --> 00:05:34,000
 okay

239
00:05:34,000 --> 00:05:39,919
並且過濾器的數量從 64 增加到 128，再到 256，再到 512

240
00:05:34,000 --> 00:05:39,919
 and the number of filters are going up from 64 to 128 to 256 to 512

241
00:05:39,919 --> 00:05:43,759
完全相同的結構我們在自動編碼器中看到過

242
00:05:39,919 --> 00:05:43,759
 exactly the same structure we saw as part of our auto encoder

243
00:05:43,759 --> 00:05:44,479
好的

244
00:05:43,759 --> 00:05:44,479
 okay

245
00:05:44,479 --> 00:05:50,639
綠色箭頭表示上卷積，這可以是上採樣

246
00:05:44,479 --> 00:05:50,639
 and the green arrows represent up convolution this can be upscaling up sampling sorry

247
00:05:50,639 --> 00:05:53,360
或上卷積轉換 2D 反向

248
00:05:50,639 --> 00:05:53,360
 or up convolution convert 2d transpose

249
00:05:53,360 --> 00:05:57,680
這些是綠色箭頭

250
00:05:53,360 --> 00:05:57,680
 and these are the green arrows

251
00:05:57,680 --> 00:06:00,880
然後你會看到藍色箭頭，它們是傳遞的

252
00:05:57,680 --> 00:06:00,880
 and then you see the blue arrows that are conve

253
00:06:00,880 --> 00:06:03,600
這裡的兩者都是解碼器的一部分

254
00:06:00,880 --> 00:06:03,600
 both here as part of decoder

255
00:06:03,600 --> 00:06:05,680
以及這裡作為編碼器的一部分

256
00:06:03,600 --> 00:06:05,680
 and here as part of encoder

257
00:06:05,680 --> 00:06:08,080
然後你會得到你的輸出分段地圖

258
00:06:05,680 --> 00:06:08,080
 and then you get your output segmented map

259
00:06:08,080 --> 00:06:10,319
現在讓我們來看一下 256x256

260
00:06:08,080 --> 00:06:10,319
 now let's look at this for 256 by 256

261
00:06:10,319 --> 00:06:13,440
因為這樣很方便，我們一直在使用 256 張圖像

262
00:06:10,319 --> 00:06:13,440
 because it makes it easy we have been working with 256 images

263
00:06:13,440 --> 00:06:15,360
所以讓我們看看這裡的相同結構

264
00:06:13,440 --> 00:06:15,360
 so let's look at the same structure here

265
00:06:15,360 --> 00:06:16,000
好的

266
00:06:15,360 --> 00:06:16,000
 okay

267
00:06:16,000 --> 00:06:19,759
所以我的輸入圖像是 256 乘 256

268
00:06:16,000 --> 00:06:19,759
 so my input image is 256 by 256

269
00:06:19,759 --> 00:06:21,199
一個通道

270
00:06:19,759 --> 00:06:21,199
 one channel

271
00:06:21,199 --> 00:06:24,000
假設我的輸入圖像不是彩色的，而是灰階的

272
00:06:21,199 --> 00:06:24,000
 let's just say my input image is not color it's grayscale

273
00:06:24,000 --> 00:06:27,520
我的意思是可以是三個，但現在假設是只有一個

274
00:06:24,000 --> 00:06:27,520
 i mean it can be three but for now let's say one

275
00:06:27,520 --> 00:06:30,400
在前兩層卷積之後

276
00:06:27,520 --> 00:06:30,400
 after the first two convolution layers

277
00:06:30,400 --> 00:06:33,919
我在那裡有 64 個過濾器

278
00:06:30,400 --> 00:06:33,919
 i have 64 filters right there

279
00:06:33,919 --> 00:06:36,319
然後我執行 2x2 的最大池化

280
00:06:33,919 --> 00:06:36,319
 and then i perform max pooling 2 by 2

281
00:06:36,319 --> 00:06:39,919
這意味著我的 256 變成 128。

282
00:06:36,319 --> 00:06:39,919
 which means my 256 becomes 128.

283
00:06:39,919 --> 00:06:43,840
所以這個維度是 128 乘 128

284
00:06:39,919 --> 00:06:43,840
 so this dimension is 128 by 128

285
00:06:43,840 --> 00:06:47,440
然後我們使用多少個濾波器進行卷積操作

286
00:06:43,840 --> 00:06:47,440
 and then we perform convolutional operation with how many filters

287
00:06:47,440 --> 00:06:50,000
現在 128 個過濾器

288
00:06:47,440 --> 00:06:50,000
 now 128 filters

289
00:06:50,000 --> 00:06:51,199
然後進行最大池化

290
00:06:50,000 --> 00:06:51,199
 and then max pooling

291
00:06:51,199 --> 00:06:53,440
這意味著我的 128 變成 64

292
00:06:51,199 --> 00:06:53,440
 which means my 128 becomes 64

293
00:06:53,440 --> 00:06:56,639
然後我將濾波器的數量加倍到 256

294
00:06:53,440 --> 00:06:56,639
 and then i double the number of filters to 256

295
00:06:56,639 --> 00:06:59,120
我一直做到這裡為止

296
00:06:56,639 --> 00:06:59,120
 and i do that all the way up to down here

297
00:06:59,120 --> 00:07:01,759
在這裡我有 1024

298
00:06:59,120 --> 00:07:01,759
 where i have 1024

299
00:07:01,759 --> 00:07:02,319
功能

300
00:07:01,759 --> 00:07:02,319
 features

301
00:07:02,319 --> 00:07:07,120
並且僅在我的影像尺寸中為 16x16

302
00:07:02,319 --> 00:07:07,120
 and only 16 by 16 in terms of my image dimensions

303
00:07:07,120 --> 00:07:09,440
現在我想上升

304
00:07:07,120 --> 00:07:09,440
 now i want to go up

305
00:07:09,440 --> 00:07:12,560
從 1024 我去戰鬥得很好，為什麼

306
00:07:09,440 --> 00:07:12,560
 from 1024 i go to fight well why

307
00:07:12,560 --> 00:07:15,440
因為我有二乘二的上卷積意思

308
00:07:12,560 --> 00:07:15,440
 because i have up convolution of two by two meaning

309
00:07:15,440 --> 00:07:17,840
或把這看作上採樣

310
00:07:15,440 --> 00:07:17,840
 or think of this as up sampling

311
00:07:17,840 --> 00:07:22,240
好的，抱歉，這裡的大小應該是 32 乘 32，這就是我所說的

312
00:07:17,840 --> 00:07:22,240
 okay sorry the size here would be 32 by 32 this is what i meant

313
00:07:22,240 --> 00:07:22,800
好的

314
00:07:22,240 --> 00:07:22,800
 yeah

315
00:07:22,800 --> 00:07:26,319
所以從 16 x 16 開始，我的尺寸會變成 32 x 32

316
00:07:22,800 --> 00:07:26,319
 so from 16 by 16 my size would be 32 by 32

317
00:07:26,319 --> 00:07:29,840
因為我有 2 x 2 的上採樣。

318
00:07:26,319 --> 00:07:29,840
 because i have an up sampling of 2 by 2.

319
00:07:29,840 --> 00:07:30,639
好的

320
00:07:29,840 --> 00:07:30,639
 okay

321
00:07:30,639 --> 00:07:34,400
並且我從 10 24 個濾波器增加到 512 個

322
00:07:30,639 --> 00:07:34,400
 and i'm going from 10 24 filters to 512

323
00:07:34,400 --> 00:07:36,319
然後是兩次卷積

324
00:07:34,400 --> 00:07:36,319
 and then two convolutions

325
00:07:36,319 --> 00:07:38,400
相同的東西重複

326
00:07:36,319 --> 00:07:38,400
 same thing repeating

327
00:07:38,400 --> 00:07:39,840
向上卷積

328
00:07:38,400 --> 00:07:39,840
 up convolution

329
00:07:39,840 --> 00:07:42,720
所以你的大小從 32 增加到 64。

330
00:07:39,840 --> 00:07:42,720
 so your size goes from 32 to 64.

331
00:07:42,720 --> 00:07:44,479
然後是卷積

332
00:07:42,720 --> 00:07:44,479
 and then convolutions

333
00:07:44,479 --> 00:07:45,440
以此類推

334
00:07:44,479 --> 00:07:45,440
 and so on

335
00:07:45,440 --> 00:07:45,759
現在

336
00:07:45,440 --> 00:07:45,759
 now

337
00:07:45,759 --> 00:07:48,479
串接在哪裡出現

338
00:07:45,759 --> 00:07:48,479
 where does the concatenation come into picture

339
00:07:48,479 --> 00:07:49,840
所以我們來看看這個

340
00:07:48,479 --> 00:07:49,840
 so let's just look at this

341
00:07:49,840 --> 00:07:52,160
因為那邊不太擁擠對吧

342
00:07:49,840 --> 00:07:52,160
 because it's not too busy up there right

343
00:07:52,160 --> 00:07:53,360
所以你有

344
00:07:52,160 --> 00:07:53,360
 so you have

345
00:07:53,360 --> 00:07:56,960
這個操作後你會有 128

346
00:07:53,360 --> 00:07:56,960
 after this operation you have 128

347
00:07:56,960 --> 00:07:58,639
就在那裡的過濾器功能

348
00:07:56,960 --> 00:07:58,639
 filters features right there

349
00:07:58,639 --> 00:08:02,080
好的，從 256 你會降到 128

350
00:07:58,639 --> 00:08:02,080
 okay from 256 you're going to 128

351
00:08:02,080 --> 00:08:10,000
但是我們將從這裡添加的 128 個數據合併到這些數據中

352
00:08:02,080 --> 00:08:10,000
 but then we are adding the 128 that are coming from here to these right there

353
00:08:10,000 --> 00:08:10,560
好的

354
00:08:10,000 --> 00:08:10,560
 okay

355
00:08:10,560 --> 00:08:12,960
所以這就是我們正在串聯的內容

356
00:08:10,560 --> 00:08:12,960
 so that's what we are concatenating

357
00:08:12,960 --> 00:08:16,560
然後進行我們的卷積操作

358
00:08:12,960 --> 00:08:16,560
 and then comes our convolution operation

359
00:08:16,560 --> 00:08:20,639
然後我們進行上採樣

360
00:08:16,560 --> 00:08:20,639
 and then comes our up up sampling right there

361
00:08:20,639 --> 00:08:26,400
還有卷積操作，濾波器數量為 128，顯然是對的

362
00:08:20,639 --> 00:08:26,400
 and the convolution operation with a filters number of filters of 128 obviously right

363
00:08:26,400 --> 00:08:28,800
所以這裡有 128 加 128

364
00:08:26,400 --> 00:08:28,800
 so here you have 128 plus 128

365
00:08:28,800 --> 00:08:34,080
但接下來的卷積，我們是說，把它轉換成 128 個濾波器

366
00:08:28,800 --> 00:08:34,080
 but then the convolution right there we are saying that hey convert that into 128 filters

367
00:08:34,080 --> 00:08:36,958
所以在卷積操作之後，你會有 128 個

368
00:08:34,080 --> 00:08:36,958
 so after the convolution operation you have 128

369
00:08:36,958 --> 00:08:39,200
影像大小為 128 x 128。

370
00:08:36,958 --> 00:08:39,200
 and the image size is 128 128.

371
00:08:39,200 --> 00:08:42,880
所以這個藍色的

372
00:08:39,200 --> 00:08:42,880
 so this blue

373
00:08:42,880 --> 00:08:46,080
就是那些以藍色顯示的部分

374
00:08:42,880 --> 00:08:46,080
 the ones that are represented in blue right there

375
00:08:46,080 --> 00:08:50,560
他們代表來自解碼器的特徵

376
00:08:46,080 --> 00:08:50,560
 they are representing the features coming from the decoder

377
00:08:50,560 --> 00:08:52,320
和那個透明的

378
00:08:50,560 --> 00:08:52,320
 and the one that is transparent

379
00:08:52,320 --> 00:08:56,880
像這裡的白色方框，這裡有來自這裡的特徵

380
00:08:52,320 --> 00:08:56,880
 box like the white box right here there are the features coming from here

381
00:08:56,880 --> 00:09:02,880
這意味著這個白色框包含我們非常需要的空間資訊

382
00:08:56,880 --> 00:09:02,880
 that means this white box contains spatial information that's much needed for us

383
00:09:02,880 --> 00:09:05,200
而這個藍色框包含

384
00:09:02,880 --> 00:09:05,200
 and this blue box contains

385
00:09:05,200 --> 00:09:09,440
用來理解特徵所需的特徵資訊。我希望這樣能讓你明白

386
00:09:05,200 --> 00:09:09,440
 the feature information that's needed to understand the features i hope this makes sense

387
00:09:09,440 --> 00:09:12,080
所以我們在離開時做的完全相同

388
00:09:09,440 --> 00:09:12,080
 so we are doing exactly the same on the way out

389
00:09:12,080 --> 00:09:12,720
最後

390
00:09:12,080 --> 00:09:12,720
 and finally

391
00:09:12,720 --> 00:09:15,920
因為這是一個，你知道的

392
00:09:12,720 --> 00:09:15,920
 because this is a you know

393
00:09:15,920 --> 00:09:21,200
一個通道的影像，我在這裡輸出，或在這個例子中我的 y 只有一個通道

394
00:09:15,920 --> 00:09:21,200
 one channel image again i'm outputting here or my y in this case has one channel

395
00:09:21,200 --> 00:09:24,640
這就是我的輸出

396
00:09:21,200 --> 00:09:24,640
 so that's my output right there

397
00:09:24,640 --> 00:09:29,279
你怎麼編碼？非常簡單，就像你在這裡看到的一樣

398
00:09:24,640 --> 00:09:29,279
 how do you code it very simple exactly the way you see it here

399
00:09:29,279 --> 00:09:35,200
對不起，我的輸入是 256 到 56 1，那是我的輸入

400
00:09:29,279 --> 00:09:35,200
 excuse me my input is 256 to 56 1 that's my input

401
00:09:35,200 --> 00:09:40,000
然後進行兩次卷積操作，每次都是三乘三

402
00:09:35,200 --> 00:09:40,000
 then comes two convolution operations right with three by three

403
00:09:40,000 --> 00:09:42,640
和 Rayleigh

404
00:09:40,000 --> 00:09:42,640
 and rayleigh

405
00:09:42,720 --> 00:09:45,600
可轉換性 可轉換性

406
00:09:42,720 --> 00:09:45,600
 convertibility convertivity

407
00:09:45,600 --> 00:09:47,519
有多少個濾鏡

408
00:09:45,600 --> 00:09:47,519
 how many filters

409
00:09:47,519 --> 00:09:52,800
64 個過濾器適用於我的操作 64 個過濾器 64 個過濾器

410
00:09:47,519 --> 00:09:52,800
 64 filters right for my operation 64 filters 64 filters

411
00:09:52,800 --> 00:09:55,519
三乘三，您可以在這裡輸入三或三乘三

412
00:09:52,800 --> 00:09:55,519
 three by three you can just type three here or three by three

413
00:09:55,519 --> 00:09:56,560
這取決於你

414
00:09:55,519 --> 00:09:56,560
 it's up to you

415
00:09:56,560 --> 00:09:59,440
它接受 Keras 也接受

416
00:09:56,560 --> 00:09:59,440
 it accepts both keras accepts both

417
00:09:59,440 --> 00:10:00,959
這是三乘三的

418
00:09:59,440 --> 00:10:00,959
 that's three by three that's

419
00:10:00,959 --> 00:10:03,120
這表示的是

420
00:10:00,959 --> 00:10:03,120
 what this is indicating

421
00:10:03,120 --> 00:10:05,839
然後激活函數是 ReLU

422
00:10:03,120 --> 00:10:05,839
 and then activation is relu

423
00:10:05,839 --> 00:10:07,760
我會將填充設定為相同

424
00:10:05,839 --> 00:10:07,760
 i'm gonna do padding equals to same

425
00:10:07,760 --> 00:10:10,720
這樣我的輸出大小會相同

426
00:10:07,760 --> 00:10:10,720
 so my output is the same size

427
00:10:10,720 --> 00:10:15,200
這裡的輸出與這個輸入 256 256 相同大小

428
00:10:10,720 --> 00:10:15,200
 output here is the same size as this input 256 256.

429
00:10:15,200 --> 00:10:16,480
我不認為原始論文

430
00:10:15,200 --> 00:10:16,480
 i don't think the original paper

431
00:10:16,480 --> 00:10:18,480
做到了這一點，因此尺寸有所變化

432
00:10:16,480 --> 00:10:18,480
 did that that's why there is a change in size

433
00:10:18,480 --> 00:10:21,040
從 572 變到 570 再變到 568

434
00:10:18,480 --> 00:10:21,040
 from 572 to 570 to 568

435
00:10:21,040 --> 00:10:23,440
這是我所想的

436
00:10:21,040 --> 00:10:23,440
 that's what i think

437
00:10:23,440 --> 00:10:26,079
在我們的情況下，我們就輸出吧

438
00:10:23,440 --> 00:10:26,079
 in our case let's just put output

439
00:10:26,079 --> 00:10:27,120
填充等於相同

440
00:10:26,079 --> 00:10:27,120
 padding equals to same

441
00:10:27,120 --> 00:10:29,519
這樣我們就不會丟失任何信息

442
00:10:27,120 --> 00:10:29,519
 so we don't lose any information there

443
00:10:29,519 --> 00:10:30,079
好的

444
00:10:29,519 --> 00:10:30,079
 okay

445
00:10:30,079 --> 00:10:33,839
所以這些是兩個卷積層

446
00:10:30,079 --> 00:10:33,839
 so these are the two con layers

447
00:10:33,839 --> 00:10:41,120
然後是最大池化，對吧？兩個卷積層之後是兩乘兩的最大池化

448
00:10:33,839 --> 00:10:41,120
 then comes max pooling right two con then comes max pooling of watt two by two

449
00:10:41,120 --> 00:10:44,800
兩兩池化的 2D 最大池化

450
00:10:41,120 --> 00:10:44,800
 max pooling 2d of pool size two by two

451
00:10:44,800 --> 00:10:49,920
接下來的兩層卷積層 128 最大池化 1.28

452
00:10:44,800 --> 00:10:49,920
 next two convolution layers 128 max pooling 1.28

453
00:10:49,920 --> 00:10:54,480
最大池化然後 256 最大池化

454
00:10:49,920 --> 00:10:54,480
 max pooling then 256 max pooling

455
00:10:55,279 --> 00:10:56,079
好的

456
00:10:55,279 --> 00:10:56,079
 okay

457
00:10:56,079 --> 00:10:59,920
所以這部分應該非常簡單，就是編碼器部分

458
00:10:56,079 --> 00:10:59,920
 so this part should be pretty straightforward the encoder part

459
00:10:59,920 --> 00:11:03,200
這是基數 1024

460
00:10:59,920 --> 00:11:03,200
 and this is the base 1024

461
00:11:03,200 --> 00:11:04,480
就在那裡

462
00:11:03,200 --> 00:11:04,480
 right there

463
00:11:04,480 --> 00:11:06,000
你用這個 1024 做什麼？

464
00:11:04,480 --> 00:11:06,000
 what do you do with this 1024

465
00:11:06,000 --> 00:11:08,240
現在我們需要反過來做

466
00:11:06,000 --> 00:11:08,240
 now we need to go the other way around

467
00:11:08,240 --> 00:11:08,640
好的

468
00:11:08,240 --> 00:11:08,640
 okay

469
00:11:08,640 --> 00:11:12,160
所以以這個作為輸入，以 b1 作為輸入

470
00:11:08,640 --> 00:11:12,160
 so with that as input with b1 as input

471
00:11:12,160 --> 00:11:14,720
就在那裡，那是我的輸入

472
00:11:12,160 --> 00:11:14,720
 right there that's my input

473
00:11:14,720 --> 00:11:18,079
好的，我想進行一次卷積操作

474
00:11:14,720 --> 00:11:18,079
 okay i would like to do a convolution operation

475
00:11:18,079 --> 00:11:21,839
對，我想進行一次卷積操作

476
00:11:18,079 --> 00:11:21,839
 right i would like to a convolution operation

477
00:11:21,839 --> 00:11:23,839
對不起

478
00:11:21,839 --> 00:11:23,839
 excuse me

479
00:11:23,839 --> 00:11:26,959
然後連接連接

480
00:11:23,839 --> 00:11:26,959
 and then concatenate concatenate

481
00:11:26,959 --> 00:11:28,160
什麼 s4

482
00:11:26,959 --> 00:11:28,160
 what s4

483
00:11:28,160 --> 00:11:28,800
和 d1

484
00:11:28,160 --> 00:11:28,800
 and d1

485
00:11:28,800 --> 00:11:29,600
s4 是什麼

486
00:11:28,800 --> 00:11:29,600
 what is s4

487
00:11:29,600 --> 00:11:30,720
和 d1

488
00:11:29,600 --> 00:11:30,720
 and d1

489
00:11:30,720 --> 00:11:31,920
所以

490
00:11:30,720 --> 00:11:31,920
 so

491
00:11:31,920 --> 00:11:38,560
哦，我沒有處理好，我在串聯

492
00:11:31,920 --> 00:11:38,560
 oh i'm not putting well i'm concatenating

493
00:11:38,560 --> 00:11:39,360
這個

494
00:11:38,560 --> 00:11:39,360
 this

495
00:11:39,360 --> 00:11:44,880
和這個在下一步中一起串聯

496
00:11:39,360 --> 00:11:44,880
 and this together in the next step once you concatenate

497
00:11:44,880 --> 00:11:47,120
兩個卷積運算

498
00:11:44,880 --> 00:11:47,120
 two convolution operations

499
00:11:47,120 --> 00:11:50,160
戰鬥閥的連續性

500
00:11:47,120 --> 00:11:50,160
 contudy continuity of fight valve

501
00:11:50,160 --> 00:11:53,680
是的，那裡有 512

502
00:11:50,160 --> 00:11:53,680
 yeah a 512 right there

503
00:11:53,680 --> 00:11:54,160
然後來到

504
00:11:53,680 --> 00:11:54,160
 then comes

505
00:11:54,160 --> 00:11:57,760
另一個卷積操作

506
00:11:54,160 --> 00:11:57,760
 what another convolution operation

507
00:11:57,760 --> 00:11:59,040
好的，在 d1 上

508
00:11:57,760 --> 00:11:59,040
 okay on d1

509
00:11:59,040 --> 00:12:04,959
所以這裡的輸出是另一個卷積，你看到的是二乘二的卷積

510
00:11:59,040 --> 00:12:04,959
 so the output here another convolution right there you see up convolution two by two

511
00:12:04,959 --> 00:12:07,760
然後你將這兩個連接在一起，這正是

512
00:12:04,959 --> 00:12:07,760
 and then you concatenate these two that's exactly

513
00:12:07,760 --> 00:12:09,440
我們在這裡所做的

514
00:12:07,760 --> 00:12:09,440
 what we do here

515
00:12:09,440 --> 00:12:11,440
將這兩個連接起來

516
00:12:09,440 --> 00:12:11,440
 concatenate those two

517
00:12:11,440 --> 00:12:14,959
然後再進行兩次卷積操作 con con

518
00:12:11,440 --> 00:12:14,959
 and then perform two more convolution operations con con

519
00:12:14,959 --> 00:12:16,720
所以這會重複

520
00:12:14,959 --> 00:12:16,720
 so this repeats

521
00:12:16,720 --> 00:12:17,519
一路上

522
00:12:16,720 --> 00:12:17,519
 all the way

523
00:12:17,519 --> 00:12:19,839
在你獲得輸出後

524
00:12:17,519 --> 00:12:19,839
 after you get your output

525
00:12:19,839 --> 00:12:25,040
所以我希望這可以澄清你對單位的任何疑問

526
00:12:19,839 --> 00:12:25,040
 so i hope this this clears any any doubts that you have about unit

527
00:12:25,040 --> 00:12:28,480
但至少為我們建立了一個良好的基礎，以便理解單位

528
00:12:25,040 --> 00:12:28,480
 but at least establishes a nice basement for us to understand units

529
00:12:28,480 --> 00:12:31,519
在接下來的幾個影片中，我們會逐步進行

530
00:12:28,480 --> 00:12:31,519
 as we go along in the next few videos

531
00:12:31,519 --> 00:12:34,560
讓我們跳到程式碼，複製並貼上這個

532
00:12:31,519 --> 00:12:34,560
 let's jump to the code copy paste this

533
00:12:34,560 --> 00:12:36,839
並查看 model.summary

534
00:12:34,560 --> 00:12:36,839
 and see just model.summary

535
00:12:36,839 --> 00:12:38,240
好的

536
00:12:36,839 --> 00:12:38,240
 okay

537
00:12:38,240 --> 00:12:38,560
好的

538
00:12:38,240 --> 00:12:38,560
 okay

539
00:12:38,560 --> 00:12:42,240
所以這就是我所做的，我只是導入了相關的

540
00:12:38,560 --> 00:12:42,240
 so here you go all i did is imported the relevant

541
00:12:42,240 --> 00:12:45,519
這裡的庫，順便提一下，來自 keras.layers

542
00:12:42,240 --> 00:12:45,519
 libraries here by the way from keras.layers

543
00:12:45,519 --> 00:12:47,279
事實上，一個好的

544
00:12:45,519 --> 00:12:47,279
 in fact a good

545
00:12:47,279 --> 00:12:53,760
如果你正在使用 TensorFlow 2 或更高版本，建議使用 TensorFlow dot

546
00:12:47,279 --> 00:12:53,760
 practice if you're working on tensorflow 2 or later is do intense tensor flow dot

547
00:12:53,760 --> 00:12:55,040
cash dot layers

548
00:12:53,760 --> 00:12:55,040
 cash dot layers

549
00:12:55,040 --> 00:12:57,839
因為這可能是處理這種情況的最佳方法

550
00:12:55,040 --> 00:12:57,839
 because that's probably the best way to deal with that

551
00:12:57,839 --> 00:12:59,360
和你需要記住的一點是，如果你這麼做，你需要對所有 Keras 進行這樣的處理

552
00:12:57,839 --> 00:12:59,360
 and one thing you

553
00:12:59,360 --> 00:13:02,560
好的，你不能混合使用，否則會出現一些奇怪的錯誤

554
00:12:59,360 --> 00:13:02,560
 have to remember is if you do that you do that for all keras

555
00:13:02,560 --> 00:13:05,200
好的，你不能混合使用，否則會出現一些奇怪的錯誤

556
00:13:02,560 --> 00:13:05,200
 okay you cannot mix and match it throws some weird error

557
00:13:05,200 --> 00:13:08,480
然後你會花一整天試圖弄明白那個錯誤的意思

558
00:13:05,200 --> 00:13:08,480
 and you'll spend all day trying to figure out what that error means

559
00:13:08,480 --> 00:13:12,480
所以從 keras.layers

560
00:13:08,480 --> 00:13:12,480
 so from keras.layers

561
00:13:12,480 --> 00:13:15,120
我們得到的是 con 2d

562
00:13:12,480 --> 00:13:15,120
 we are getting con 2d

563
00:13:15,120 --> 00:13:16,399
最大池化

564
00:13:15,120 --> 00:13:16,399
 max pooling

565
00:13:16,399 --> 00:13:18,800
上採樣 連接 記住

566
00:13:16,399 --> 00:13:18,800
 up sampling concatenate remember

567
00:13:18,800 --> 00:13:21,360
這些都是我們需要的東西，我還在導入

568
00:13:18,800 --> 00:13:21,360
 these are all the things that we need i'm also importing

569
00:13:21,360 --> 00:13:23,760
2d 轉置以便替換

570
00:13:21,360 --> 00:13:23,760
 con 2d transpose in case you want to replace

571
00:13:23,760 --> 00:13:25,200
用這個替換你的上採樣

572
00:13:23,760 --> 00:13:25,200
 your up sampling with this

573
00:13:25,200 --> 00:13:30,560
或者你知道，僅僅做一些測試批量正則化丟棄

574
00:13:25,200 --> 00:13:30,560
 or you know just to do some testing batch normalization dropout

575
00:13:30,560 --> 00:13:33,920
而且我甚至不確定我們是否在使用 Lambda

576
00:13:30,560 --> 00:13:33,920
 and i'm not even sure if we are using lambda

577
00:13:33,920 --> 00:13:35,600
但

578
00:13:33,920 --> 00:13:35,600
 but

579
00:13:35,600 --> 00:13:38,560
是的，我在那裡不使用 Lambda

580
00:13:35,600 --> 00:13:38,560
 yeah i'm not using lambda right there

581
00:13:38,560 --> 00:13:40,160
但

582
00:13:38,560 --> 00:13:40,160
 but

583
00:13:40,160 --> 00:13:45,360
我們來進口這些，我覺得我們需要連接

584
00:13:40,160 --> 00:13:45,360
 let's go ahead and import these i think we need to connect

585
00:13:46,240 --> 00:13:49,519
目前執行時間可以不需要 GPU

586
00:13:46,240 --> 00:13:49,519
 and for now the run time can be you don't need gpu

587
00:13:49,519 --> 00:13:53,279
因為我們不會執行其他任務

588
00:13:49,519 --> 00:13:53,279
 because we are not going to run anything other than other

589
00:13:53,279 --> 00:13:55,360
我的意思是我們不會訓練模型

590
00:13:53,279 --> 00:13:55,360
 i mean we are not going to train a model

591
00:13:55,360 --> 00:13:58,399
那麼我們接著來導入我們的庫

592
00:13:55,360 --> 00:13:58,399
 so let's go ahead and import our libraries

593
00:13:58,399 --> 00:14:01,120
然後這段代碼正是

594
00:13:58,399 --> 00:14:01,120
 and then this code is exactly

595
00:14:01,120 --> 00:14:05,519
我在演示中展示給你的部分，對吧，我是說你有貢獻

596
00:14:01,120 --> 00:14:05,519
 what i showed you as part of the presentation right i mean you have contri

597
00:14:05,519 --> 00:14:06,560
現在

598
00:14:05,519 --> 00:14:06,560
 now

599
00:14:06,560 --> 00:14:13,440
我更正一下，這不完全是在卷積層之間，我加了一個 dropout 層

600
00:14:06,560 --> 00:14:13,440
 i correct myself this is not exactly in between the convolution layers i added a dropout layer

601
00:14:13,440 --> 00:14:13,839
如果你

602
00:14:13,440 --> 00:14:13,839
 if you

603
00:14:13,839 --> 00:14:16,800
如果你，整個重點是我想讓你看到的是

604
00:14:13,839 --> 00:14:16,800
 if you the whole point is i want to show you that it's

605
00:14:16,800 --> 00:14:22,560
是的，結構，原始結構顯示了你 con con 最大池化

606
00:14:16,800 --> 00:14:22,560
 yeah the structure the original structure shows you con con max polling

607
00:14:22,560 --> 00:14:24,320
你可以添加批次正規化

608
00:14:22,560 --> 00:14:24,320
 you can add batch normalization

609
00:14:24,320 --> 00:14:28,160
在這些欄位之間，您可以添加，您可以添加

610
00:14:24,320 --> 00:14:28,160
 as part of in between these columns you can add you can add

611
00:14:28,160 --> 00:14:32,000
我討厭這個東西，您可以添加丟失值

612
00:14:28,160 --> 00:14:32,000
 i hate this thing you can add dropout

613
00:14:32,000 --> 00:14:36,959
您知道，作為正則化項，因此您可以在這些之間添加一些

614
00:14:32,000 --> 00:14:36,959
 you know just as a regularization term so you can add some of these in between

615
00:14:36,959 --> 00:14:39,760
但是整體結構是你有 con

616
00:14:36,959 --> 00:14:39,760
 but the overall structure is you have con

617
00:14:39,760 --> 00:14:45,920
con 最大池化 con con 最大池化 我在中間添加了 dropout con con 最大池化

618
00:14:39,760 --> 00:14:45,920
 con max pooling con con max pulling i'm adding dropout in between con con max pooling

619
00:14:45,920 --> 00:14:51,760
和昂貴的路徑在這個例子中，除了僅僅執行卷積

620
00:14:45,920 --> 00:14:51,760
 and expensive path in this example instead of just performing convolution

621
00:14:51,760 --> 00:14:53,440
操作，我認為這很重要

622
00:14:51,760 --> 00:14:53,440
 operation i think this is important

623
00:14:53,440 --> 00:14:55,120
所以讓我切換回來

624
00:14:53,440 --> 00:14:55,120
 so let me switch back

625
00:14:55,120 --> 00:15:00,480
所以我可以向你展示這裡，我們正在使用 con con 最大池化

626
00:14:55,120 --> 00:15:00,480
 so i can show you this right here right here we are using con con max pooling

627
00:15:00,480 --> 00:15:04,399
在我的例子中，在卷積層之間我加入了 dropout

628
00:15:00,480 --> 00:15:04,399
 in my example between the convolution layers i added dropout

629
00:15:04,399 --> 00:15:11,040
只是為了確保我的模型不會過擬合，這就是擴展路徑中我進行了卷積操作

630
00:15:04,399 --> 00:15:11,040
 just to make sure my model doesn't over fit that's it in the expansion path i did convolution operation

631
00:15:11,040 --> 00:15:15,040
然後就在那裡進行了上採樣

632
00:15:11,040 --> 00:15:15,040
 and then did the up sampling right there

633
00:15:15,040 --> 00:15:16,639
可以調整到那個大小

634
00:15:15,040 --> 00:15:16,639
 okay to that size

635
00:15:16,639 --> 00:15:18,480
我做了卷積運算

636
00:15:16,639 --> 00:15:18,480
 i did convolution operation

637
00:15:18,480 --> 00:15:22,160
將圖像上採樣到特定大小，然後進行卷積

638
00:15:18,480 --> 00:15:22,160
 up sampling to that specific size followed by the convolution

639
00:15:22,160 --> 00:15:23,600
操作正確，所以連接

640
00:15:22,160 --> 00:15:23,600
 operation right so con

641
00:15:23,600 --> 00:15:28,399
然後當你做 2d 轉置時，卷積就會在那裡

642
00:15:23,600 --> 00:15:28,399
 and then up sample when you do con 2d transpose the conv is right there

643
00:15:28,399 --> 00:15:30,160
轉置是內建的

644
00:15:28,399 --> 00:15:30,160
 and the transpose is built in

645
00:15:30,160 --> 00:15:32,959
是的，所以你不會在兩個不同的步驟中進行這個

646
00:15:30,160 --> 00:15:32,959
 yeah so you don't you don't do this in two different steps

647
00:15:32,959 --> 00:15:35,600
所以讓我們回到之前的內容

648
00:15:32,959 --> 00:15:35,600
 so let's jump back

649
00:15:35,600 --> 00:15:36,480
那麼這樣

650
00:15:35,600 --> 00:15:36,480
 so there you go

651
00:15:36,480 --> 00:15:39,040
所以這裡我有 convert2d 轉置

652
00:15:36,480 --> 00:15:39,040
 so here i have convert2d transpose

653
00:15:39,040 --> 00:15:40,480
然後我在進行串接

654
00:15:39,040 --> 00:15:40,480
 and then i'm concatenating

655
00:15:40,480 --> 00:15:42,320
哦，上帝，幫助

656
00:15:40,480 --> 00:15:42,320
 oh god the help

657
00:15:42,320 --> 00:15:43,680
然後我在串接

658
00:15:42,320 --> 00:15:43,680
 and then i'm concatenating

659
00:15:43,680 --> 00:15:45,839
然後另一個 con 2d

660
00:15:43,680 --> 00:15:45,839
 and then another con 2d

661
00:15:45,839 --> 00:15:48,240
然後另一位貢獻者也非常相似

662
00:15:45,839 --> 00:15:48,240
 and then another contributor right very similar

663
00:15:48,240 --> 00:15:49,040
所以這就是

664
00:15:48,240 --> 00:15:49,040
 so this is

665
00:15:49,040 --> 00:15:49,839
我們是如何建立的

666
00:15:49,040 --> 00:15:49,839
 how we built

667
00:15:49,839 --> 00:15:51,600
然後我嘗試去

668
00:15:49,839 --> 00:15:51,600
 and then i'm trying to

669
00:15:51,600 --> 00:15:53,440
印出 model dot summary

670
00:15:51,600 --> 00:15:53,440
 print out model dot summary

671
00:15:53,440 --> 00:15:55,600
讓我們繼續

672
00:15:53,440 --> 00:15:55,600
 and let us go ahead

673
00:15:55,600 --> 00:15:58,880
並將摘要列印出來，這就是我們的單元模型

674
00:15:55,600 --> 00:15:58,880
 and print the summary out and there you go here is our unit model

675
00:15:58,880 --> 00:16:03,120
所以一旦你理解了結構，建立單元其實非常簡單

676
00:15:58,880 --> 00:16:03,120
 so building a unit is once you understand the structure this is very simple actually

677
00:16:03,120 --> 00:16:08,160
實際上，你可以使用特定功能來定義這裡的單元

678
00:16:03,120 --> 00:16:08,160
 in fact you can use specific functions to define the unit here

679
00:16:08,160 --> 00:16:10,399
如果你看到重複的內容

680
00:16:08,160 --> 00:16:10,399
 if you see what is repeating

681
00:16:10,399 --> 00:16:13,600
連續性掉線造成的最大輪詢

682
00:16:10,399 --> 00:16:13,600
 continuity dropout contributing max polling

683
00:16:13,600 --> 00:16:15,680
相反的掉線，相反的最大輪詢

684
00:16:13,600 --> 00:16:15,680
 contrary dropout contrary max polling

685
00:16:15,680 --> 00:16:18,240
所以這整個東西是一個區塊

686
00:16:15,680 --> 00:16:18,240
 so this entire thing is one block

687
00:16:18,240 --> 00:16:21,519
這整個東西是另一個區塊，這是另一個區塊，對吧

688
00:16:18,240 --> 00:16:21,519
 this entire thing is another block this is another block right

689
00:16:21,519 --> 00:16:24,959
這樣你就可以僅為卷積區塊定義一個函數

690
00:16:21,519 --> 00:16:24,959
 so you can define a function only for the convolution block

691
00:16:24,959 --> 00:16:27,839
然後只需改變濾波器的數量，就是這樣

692
00:16:24,959 --> 00:16:27,839
 and then just change the number of filters that's it

693
00:16:27,839 --> 00:16:31,839
因為這是唯一會改變的東西，所以如果你想要更乾淨的代碼

694
00:16:27,839 --> 00:16:31,839
 because that's the only thing that's changing right so if you want a cleaner code

695
00:16:31,839 --> 00:16:34,560
這是一種更好的做事方式

696
00:16:31,839 --> 00:16:34,560
 that's a much better way of doing things

697
00:16:34,560 --> 00:16:35,120
好的

698
00:16:34,560 --> 00:16:35,120
 okay

699
00:16:35,120 --> 00:16:38,880
所以這是一個簡單的介紹

700
00:16:35,120 --> 00:16:38,880
 so this is a quick introduction of

701
00:16:38,880 --> 00:16:45,279
一般來說，我一直承諾要談論上採樣與 2D 轉置卷積

702
00:16:38,880 --> 00:16:45,279
 the unit in general i keep promising to talk about up sampling versus con 2d transpose

703
00:16:45,279 --> 00:16:49,120
我保證我會在下一個影片中做到這一點

704
00:16:45,279 --> 00:16:49,120
 i i promise that i'll do that in the next video

705
00:16:49,120 --> 00:16:52,399
我覺得你首先了解這點非常重要

706
00:16:49,120 --> 00:16:52,399
 i thought it's very important for you to understand this first

707
00:16:52,399 --> 00:16:54,959
這樣你就知道我們所說的上採樣是什麼意思

708
00:16:52,399 --> 00:16:54,959
 so you know what we mean by up sampling

709
00:16:54,959 --> 00:16:56,480
以及 2D 轉置

710
00:16:54,959 --> 00:16:56,480
 and con 2d transpose

711
00:16:56,480 --> 00:17:00,800
然後討論這兩個，所以請繼續關注下一個視頻

712
00:16:56,480 --> 00:17:00,800
 and then talk about these these two so please stay tuned for the next video

713
00:17:00,800 --> 00:17:04,000
並訂閱這個頻道，謝謝

714
00:17:00,800 --> 00:17:04,000
 and subscribe to this channel thank you

